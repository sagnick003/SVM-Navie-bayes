{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SVM & Naive bayes\n",
        "\n",
        "Assignment Questions\n",
        "\n",
        "Theoretical\n",
        "\n",
        "Q1. What is a Support Vector Machine (SVM)?\n",
        "\n",
        "A Support Vector Machine (SVM) is a supervised learning algorithm used for classification and regression. It finds the optimal hyperplane that separates data points of different classes with the maximum margin.\n",
        "\n",
        "Q2. What is the difference between Hard Margin and Soft Margin SVM?\n",
        "\n",
        "Hard Margin SVM assumes data is perfectly separable and does not allow misclassification, while Soft Margin SVM allows some misclassifications using a penalty parameter (C) to handle noisy or non-linear data.\n",
        "\n",
        "Q3. What is the mathematical intuition behind SVM?\n",
        "\n",
        "SVM maximizes the margin between classes by minimizing\n",
        "1\n",
        "2\n",
        "‚à£\n",
        "‚à£\n",
        "ùë§\n",
        "‚à£\n",
        "‚à£\n",
        "2\n",
        "2\n",
        "1\n",
        "\t‚Äã\n",
        "\n",
        "‚à£‚à£w‚à£‚à£\n",
        "2\n",
        " subject to\n",
        "ùë¶\n",
        "ùëñ\n",
        "(\n",
        "ùë§\n",
        "‚ãÖ\n",
        "ùë•\n",
        "ùëñ\n",
        "+\n",
        "ùëè\n",
        ")\n",
        "‚â•\n",
        "1\n",
        "y\n",
        "i\n",
        "\t‚Äã\n",
        "\n",
        "(w‚ãÖx\n",
        "i\n",
        "\t‚Äã\n",
        "\n",
        "+b)‚â•1. A larger margin implies better generalization of the classifier.\n",
        "\n",
        "Q4. What is the role of Lagrange Multipliers in SVM?\n",
        "\n",
        "Lagrange multipliers are used to convert the constrained optimization problem into its dual form, making it easier to solve. They help identify support vectors and enable the use of kernel functions.\n",
        "\n",
        "Q5. What are Support Vectors in SVM?\n",
        "\n",
        "Support Vectors are the data points closest to the separating hyperplane. They define the position and orientation of the hyperplane, and removing them can change the decision boundary.\n",
        "\n",
        "Q6. What is a Support Vector Classifier (SVC)?\n",
        "\n",
        "A Support Vector Classifier (SVC) is the practical version of SVM that uses a soft margin to allow some misclassifications. It balances maximizing the margin and minimizing classification errors.\n",
        "\n",
        "Q7. What is a Support Vector Regressor (SVR)?\n",
        "\n",
        "Support Vector Regression (SVR) adapts SVM for regression by fitting a function within an epsilon margin. Only data points outside this margin become support vectors and affect the model.\n",
        "\n",
        "Q8. What is the Kernel Trick in SVM?\n",
        "\n",
        "The Kernel Trick allows SVM to perform non-linear classification by mapping input data to a higher-dimensional space using kernel functions like linear, polynomial, or RBF, without explicit transformation.\n",
        "\n",
        "Q9. Compare Linear Kernel, Polynomial Kernel, and RBF Kernel.\n",
        "\n",
        "Linear Kernel is best for linearly separable data, Polynomial Kernel handles moderate non-linearity, and RBF Kernel captures complex relationships but may overfit if not tuned properly.\n",
        "\n",
        "Q10. What is the effect of the C parameter in SVM?\n",
        "\n",
        "The C parameter controls the trade-off between maximizing the margin and minimizing classification errors. A high C reduces errors but may overfit, while a low C increases margin but may underfit.\n",
        "\n",
        "Q11. What is the role of the Gamma parameter in RBF Kernel SVM?\n",
        "\n",
        "Gamma determines how far the influence of a training sample reaches. A high gamma means the model is more complex and may overfit, while a low gamma gives smoother, simpler boundaries.\n",
        "\n",
        "Q12. What is the Na√Øve Bayes classifier, and why is it called \"Na√Øve\"?\n",
        "\n",
        "Na√Øve Bayes is a probabilistic classifier based on Bayes‚Äô theorem. It is called ‚Äúna√Øve‚Äù because it assumes that all features are conditionally independent given the class label.\n",
        "\n",
        "Q13. What is Bayes‚Äô Theorem?\n",
        "\n",
        "Bayes' Theorem is a powerful mathematical formula that is used to update the probability of a hypothesis ($A$) when new evidence ($B$) is introduced. It provides a way to logically revise an initial belief (the prior probability) based on observable data (the likelihood) to get a new, more accurate belief (the posterior probability).\n",
        "\n",
        "Formula and InterpretationThe formula for Bayes' Theorem is:$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
        "\n",
        "\n",
        "\n",
        "Q14. Explain the differences between Gaussian, Multinomial, and Bernoulli Na√Øve Bayes.\n",
        "Gaussian NB handles continuous features, Multinomial NB is used for count data like word frequencies, and Bernoulli NB is used for binary features indicating presence or absence.\n",
        "\n",
        "Q15. When should you use Gaussian Na√Øve Bayes over other variants?\n",
        "Gaussian Na√Øve Bayes should be used when features are continuous and follow a normal (Gaussian) distribution, such as in sensor or medical data.\n",
        "\n",
        "Q16. What are the key assumptions made by Na√Øve Bayes?\n",
        "Na√Øve Bayes assumes that features are conditionally independent given the class label and that each feature contributes equally to the outcome.\n",
        "\n",
        "Q17. What are the advantages and disadvantages of Na√Øve Bayes?\n",
        "Advantages: Simple, fast, and effective with small or high-dimensional data.\n",
        "Disadvantages: Assumes feature independence and can perform poorly when features are correlated.\n",
        "\n",
        "Q18. Why is Na√Øve Bayes a good choice for text classification?\n",
        "Na√Øve Bayes works well for text data because word occurrences are nearly independent, and it efficiently handles high-dimensional and sparse data like TF-IDF vectors.\n",
        "\n",
        "Q19. Compare SVM and Na√Øve Bayes for classification tasks.\n",
        "SVM is a discriminative model focusing on decision boundaries, while Na√Øve Bayes is a generative model based on probabilities. SVM is slower but more accurate; Na√Øve Bayes is faster but assumes independence.\n",
        "\n",
        "Q20. How does Laplace Smoothing help in Na√Øve Bayes?\n",
        "Laplace Smoothing prevents zero probabilities for unseen features by adding one to feature counts. This ensures all probabilities remain non-zero and improves model robustness.\n",
        "\n",
        "Practical\n",
        "\n",
        "21. Write a Python program to train an SVM Classifier on the Iris dataset and evaluate accuracy."
      ],
      "metadata": {
        "id": "7hkEH18yeH_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# The Iris dataset is a classic and simple dataset for classification tasks.\n",
        "print(\"Loading Iris dataset...\")\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features (Sepal length, Sepal width, Petal length, Petal width)\n",
        "y = iris.target # Target (Species: Setosa, Versicolor, Virginica)\n",
        "\n",
        "# --- 2. Split Data into Training and Testing Sets ---\n",
        "# We split the data to evaluate how well the model generalizes to unseen data.\n",
        "# test_size=0.3 means 30% of the data will be used for testing, and 70% for training.\n",
        "# random_state ensures reproducibility.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Total samples: {len(X)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 3. Initialize and Train the SVM Classifier ---\n",
        "# We use the Support Vector Classifier (SVC). The default kernel is 'rbf' (Radial Basis Function),\n",
        "# which is often highly effective for non-linear classification tasks like this.\n",
        "print(\"Initializing and training the SVM (SVC) classifier...\")\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "print(\"Training complete.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 4. Make Predictions ---\n",
        "# Use the trained model to predict the class labels for the test set.\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# --- 5. Evaluate Accuracy ---\n",
        "# Calculate the classification accuracy by comparing predicted labels (y_pred)\n",
        "# against the true labels (y_test).\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model predictions on test set: {y_pred}\")\n",
        "print(f\"Actual labels for test set: {y_test}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# The accuracy is the percentage of correctly classified instances.\n",
        "print(f\"Classification Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# --- Example Usage (Predicting a single new sample) ---\n",
        "# Let's use the first sample from the test set as an example new flower.\n",
        "example_sample = X_test[0].reshape(1, -1)\n",
        "example_prediction = svm_model.predict(example_sample)[0]\n",
        "actual_species = iris.target_names[y_test[0]]\n",
        "predicted_species = iris.target_names[example_prediction]\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(\"Example Prediction:\")\n",
        "print(f\"Input Features: {example_sample[0]}\")\n",
        "print(f\"Actual Species: {actual_species}\")\n",
        "print(f\"Predicted Species: {predicted_species}\")"
      ],
      "metadata": {
        "id": "tP8-BCzygZqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 22.Write a Python program to train two SVM classifiers with Linear and RBF kernels on the Wine dataset, then\n",
        "compare their accuracies."
      ],
      "metadata": {
        "id": "qE6FcJe_geZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# The Wine dataset is used for multi-class classification based on chemical analysis.\n",
        "print(\"Loading Wine dataset...\")\n",
        "wine = load_wine()\n",
        "X = wine.data  # Features (13 chemical constituents)\n",
        "y = wine.target # Target (3 types of wine)\n",
        "\n",
        "# --- 2. Split Data into Training and Testing Sets ---\n",
        "# We split the data to evaluate how well the model generalizes to unseen data.\n",
        "# test_size=0.3 means 30% of the data will be used for testing, and 70% for training.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Total samples: {len(X)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 3. Initialize and Train Two SVM Classifiers ---\n",
        "\n",
        "# Classifier 1: Linear Kernel\n",
        "print(\"Initializing and training SVM with LINEAR Kernel...\")\n",
        "svm_linear = SVC(kernel='linear', random_state=42)\n",
        "svm_linear.fit(X_train, y_train)\n",
        "print(\"Linear SVM training complete.\")\n",
        "\n",
        "# Classifier 2: RBF (Radial Basis Function) Kernel\n",
        "print(\"Initializing and training SVM with RBF Kernel...\")\n",
        "svm_rbf = SVC(kernel='rbf', random_state=42)\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "print(\"RBF SVM training complete.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 4. Make Predictions ---\n",
        "y_pred_linear = svm_linear.predict(X_test)\n",
        "y_pred_rbf = svm_rbf.predict(X_test)\n",
        "\n",
        "# --- 5. Evaluate and Compare Accuracies ---\n",
        "\n",
        "# Calculate accuracy for Linear SVM\n",
        "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
        "\n",
        "# Calculate accuracy for RBF SVM\n",
        "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
        "\n",
        "print(\"--- Accuracy Comparison (Wine Dataset) ---\")\n",
        "print(f\"Linear SVM Accuracy: {accuracy_linear * 100:.2f}%\")\n",
        "print(f\"RBF SVM Accuracy:    {accuracy_rbf * 100:.2f}%\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Provide a brief analysis\n",
        "if accuracy_linear > accuracy_rbf:\n",
        "    print(\"Conclusion: The Linear kernel performed slightly better on this test set.\")\n",
        "elif accuracy_rbf > accuracy_linear:\n",
        "    print(\"Conclusion: The RBF kernel performed slightly better on this test set.\")\n",
        "else:\n",
        "    print(\"Conclusion: Both kernels achieved the same level of accuracy on this test set.\")"
      ],
      "metadata": {
        "id": "nSwDfJ5ygwbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.Write a Python program to train an SVM Regressor (SVR) on a housing dataset and evaluate it using Mean\n",
        "Squared Error (MSE)."
      ],
      "metadata": {
        "id": "XtetLmBAg6WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR # Import Support Vector Regressor\n",
        "from sklearn.metrics import mean_squared_error # Import Mean Squared Error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the California Housing dataset for regression (predicting house prices).\n",
        "print(\"Loading California Housing dataset...\")\n",
        "# Data is loaded as a Bunch object\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data    # Features (8 features like median income, house age, etc.)\n",
        "y = housing.target  # Target (Median house value, in hundreds of thousands of dollars)\n",
        "\n",
        "# --- 2. Split Data into Training and Testing Sets ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Total samples: {len(X)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 3. Initialize and Train the SVR Model ---\n",
        "# SVR is highly sensitive to feature scaling, so we'll use a pipeline to scale data\n",
        "# before feeding it to the RBF SVR model.\n",
        "print(\"Initializing and training the SVR (Support Vector Regressor) with RBF Kernel...\")\n",
        "\n",
        "# C=10 gives a decent trade-off, gamma='auto' scales well with the number of features.\n",
        "svr_model = make_pipeline(\n",
        "    StandardScaler(), # Feature scaling is crucial for SVR\n",
        "    SVR(kernel='rbf', C=10, gamma='auto')\n",
        ")\n",
        "\n",
        "svr_model.fit(X_train, y_train)\n",
        "print(\"SVR training complete.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 4. Make Predictions ---\n",
        "# Use the trained model to predict the house values for the test set.\n",
        "y_pred = svr_model.predict(X_test)\n",
        "\n",
        "# --- 5. Evaluate Performance using Mean Squared Error (MSE) ---\n",
        "\n",
        "# MSE measures the average squared difference between the estimated values and the actual value.\n",
        "# A lower MSE indicates better model performance.\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"--- Regression Evaluation (California Housing Dataset) ---\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Example: Inspecting the first few predictions vs. actual values\n",
        "print(\"Sample Predictions (Predicted vs. Actual):\")\n",
        "for i in range(5):\n",
        "    # Remember the target value is in hundreds of thousands (e.g., 2.34 means $234,000)\n",
        "    print(f\"Predicted: {y_pred[i]:.2f} | Actual: {y_test[i]:.2f}\")\n"
      ],
      "metadata": {
        "id": "aEES5mVZhIKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.Write a Python program to train an SVM Classifier with a Polynomial Kernel and visualize the decision\n",
        "boundary."
      ],
      "metadata": {
        "id": "gx4g_RBZhTa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC # Support Vector Classifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the Iris dataset for classification.\n",
        "print(\"Loading Iris dataset...\")\n",
        "iris = load_iris()\n",
        "# For 2D visualization, we only use the first two features (Sepal Length and Sepal Width)\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "\n",
        "# --- 2. Split Data into Training and Testing Sets ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Total samples: {len(X)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 3. Initialize and Train the SVM Classifier with Polynomial Kernel ---\n",
        "print(\"Initializing and training the SVC (Support Vector Classifier) with Polynomial Kernel...\")\n",
        "\n",
        "# C controls regularization, degree specifies the polynomial degree.\n",
        "svm_poly_model = make_pipeline(\n",
        "    StandardScaler(), # Scaling is highly recommended for SVM\n",
        "    SVC(kernel='poly', degree=3, C=1.0, random_state=42)\n",
        ")\n",
        "\n",
        "svm_poly_model.fit(X_train, y_train)\n",
        "print(\"Polynomial SVM training complete.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 4. Evaluate Accuracy ---\n",
        "y_pred = svm_poly_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"--- Classification Evaluation (Iris Dataset - 2 Features) ---\")\n",
        "print(f\"Polynomial SVM Accuracy on Test Set: {accuracy * 100:.2f}%\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 5. Visualization of Decision Boundary ---\n",
        "\n",
        "print(\"Generating decision boundary visualization...\")\n",
        "\n",
        "# Define the boundaries of the plot based on feature ranges\n",
        "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "\n",
        "# Create a mesh grid (a grid of points across the feature space)\n",
        "h = .02\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "# Predict the class for every point in the mesh (Z)\n",
        "# The pipeline automatically scales the mesh points before prediction\n",
        "Z = svm_poly_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot the decision boundary as a colored background\n",
        "plt.figure(1, figsize=(10, 7))\n",
        "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.RdYlBu, alpha=0.2)\n",
        "\n",
        "# Plot the training points\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train,\n",
        "            cmap=plt.cm.RdYlBu, edgecolor='k', s=60, label=\"Training Data\")\n",
        "\n",
        "# Plot the test points (using an 'X' marker for distinction)\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test,\n",
        "            cmap=plt.cm.RdYlBu, marker='X', s=80, label=\"Test Data\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(iris.feature_names[0])\n",
        "plt.ylabel(iris.feature_names[1])\n",
        "plt.title(\"SVM Classifier with Polynomial Kernel (Degree 3) Decision Boundary\")\n",
        "plt.legend()\n",
        "plt.axis('tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gYq7pKzUhjZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.Write a Python program to train a Gaussian Na√Øve Bayes classifier on the Breast Cancer dataset and\n",
        "evaluate accuracy."
      ],
      "metadata": {
        "id": "LU_49PRmhq02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer # New dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB # New classifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the Breast Cancer Wisconsin (Diagnostic) dataset for binary classification.\n",
        "print(\"Loading Breast Cancer dataset...\")\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data   # Features (30 different measurements)\n",
        "y = cancer.target # Target (Malignant or Benign)\n",
        "\n",
        "# --- 2. Split Data into Training and Testing Sets ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Total samples: {len(X)}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 3. Initialize and Train the Gaussian Na√Øve Bayes Classifier ---\n",
        "print(\"Initializing and training the Gaussian Na√Øve Bayes (GNB) Classifier...\")\n",
        "\n",
        "# GNB assumes features follow a Gaussian (Normal) distribution.\n",
        "# It doesn't require feature scaling, unlike SVM.\n",
        "gnb_model = GaussianNB()\n",
        "\n",
        "gnb_model.fit(X_train, y_train)\n",
        "print(\"Gaussian Na√Øve Bayes training complete.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 4. Make Predictions ---\n",
        "y_pred = gnb_model.predict(X_test)\n",
        "\n",
        "# --- 5. Evaluate Accuracy ---\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"--- Classification Evaluation (Breast Cancer Dataset) ---\")\n",
        "print(f\"Gaussian Na√Øve Bayes Accuracy on Test Set: {accuracy * 100:.2f}%\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Provide a brief analysis of the result\n",
        "print(\"The Na√Øve Bayes model successfully classified instances with the calculated accuracy.\")"
      ],
      "metadata": {
        "id": "6iBQzKTDhy0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "26.Write a Python program to train a Multinomial Na√Øve Bayes classifier for text classification using the 20\n",
        "Newsgroups dataset."
      ],
      "metadata": {
        "id": "AQFHybQYh8y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- Configuration ---\n",
        "# We will use a subset of the categories to make the example run quickly and focus the results.\n",
        "# The full list is: 'alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware',\n",
        "# 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles',\n",
        "# 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med',\n",
        "# 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast',\n",
        "# 'talk.politics.misc', 'talk.religion.misc'\n",
        "categories = [\n",
        "    'alt.atheism',\n",
        "    'talk.religion.misc',\n",
        "    'comp.graphics',\n",
        "    'sci.space',\n",
        "]\n",
        "# Use 80% for training and 20% for testing\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "def train_and_evaluate_mnb(categories_to_use):\n",
        "    \"\"\"\n",
        "    Loads the 20 Newsgroups dataset, trains a Multinomial Naive Bayes classifier,\n",
        "    and prints the classification report and accuracy.\n",
        "    \"\"\"\n",
        "    print(f\"--- Loading data for categories: {categories_to_use} ---\")\n",
        "\n",
        "    # 1. Load the 20 Newsgroups dataset\n",
        "    # We remove headers, footers, and quotes which often contain metadata\n",
        "    # that makes classification artificially easy.\n",
        "    newsgroups_data = fetch_20newsgroups(\n",
        "        subset='all',\n",
        "        categories=categories_to_use,\n",
        "        shuffle=True,\n",
        "        random_state=42,\n",
        "        remove=('headers', 'footers', 'quotes')\n",
        "    )\n",
        "\n",
        "    X, y = newsgroups_data.data, newsgroups_data.target\n",
        "    target_names = newsgroups_data.target_names\n",
        "\n",
        "    print(f\"Total samples loaded: {len(X)}\")\n",
        "    print(f\"Classes: {target_names}\")\n",
        "\n",
        "    # 2. Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining samples: {len(X_train)}\")\n",
        "    print(f\"Testing samples: {len(X_test)}\")\n",
        "\n",
        "    # 3. Feature Extraction (Vectorization)\n",
        "    # TfidfVectorizer converts text into a matrix of TF-IDF features.\n",
        "    # TF-IDF stands for Term Frequency-Inverse Document Frequency.\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english', # Remove common English words\n",
        "        lowercase=True,       # Convert text to lowercase\n",
        "        max_df=0.5,           # Ignore terms that appear in more than 50% of the documents\n",
        "        ngram_range=(1, 2)    # Use unigrams and bigrams\n",
        "    )\n",
        "\n",
        "    # Fit the vectorizer on the training data and transform both training and testing data\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    print(f\"Feature space size (vocabulary): {X_train_vec.shape[1]}\")\n",
        "\n",
        "    # 4. Train the Multinomial Na√Øve Bayes Classifier\n",
        "    print(\"\\n--- Training Multinomial Na√Øve Bayes Classifier ---\")\n",
        "    # MultinomialNB is well-suited for classification with discrete features (like word counts)\n",
        "    # The TF-IDF weights are treated as feature counts scaled by probability.\n",
        "    mnb_classifier = MultinomialNB()\n",
        "    mnb_classifier.fit(X_train_vec, y_train)\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "    # 5. Make Predictions\n",
        "    y_pred = mnb_classifier.predict(X_test_vec)\n",
        "\n",
        "    # 6. Evaluate the Model\n",
        "    print(\"\\n--- Model Evaluation ---\")\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "    # Print detailed classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure scikit-learn and numpy are installed:\n",
        "    # pip install scikit-learn numpy\n",
        "\n",
        "    # Run the classification\n",
        "    train_and_evaluate_mnb(categories)"
      ],
      "metadata": {
        "id": "qww6ruPWiSGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "27.Write a Python program to train an SVM Classifier with different C values and compare the decision\n",
        "boundaries visually."
      ],
      "metadata": {
        "id": "w_iGnXQDizF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- Configuration for Visualization ---\n",
        "# To visualize the decision boundary, we use only two categories to create a\n",
        "# clear binary classification problem.\n",
        "categories = [\n",
        "    'rec.autos',\n",
        "    'comp.graphics',\n",
        "]\n",
        "# Use 80% for training and 20% for testing\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "def visualize_svm_decision_boundaries(categories_to_use):\n",
        "    \"\"\"\n",
        "    Loads a subset of the 20 Newsgroups data, reduces dimensionality to 2D using PCA,\n",
        "    trains SVC with different C values, and plots the decision boundaries.\n",
        "    \"\"\"\n",
        "    print(f\"--- Loading data for categories: {categories_to_use} ---\")\n",
        "\n",
        "    # 1. Load the 20 Newsgroups dataset (binary classification)\n",
        "    newsgroups_data = fetch_20newsgroups(\n",
        "        subset='all',\n",
        "        categories=categories_to_use,\n",
        "        shuffle=True,\n",
        "        random_state=42,\n",
        "        remove=('headers', 'footers', 'quotes')\n",
        "    )\n",
        "\n",
        "    X, y = newsgroups_data.data, newsgroups_data.target\n",
        "    target_names = newsgroups_data.target_names\n",
        "\n",
        "    print(f\"Total samples loaded: {len(X)}\")\n",
        "    print(f\"Classes: {target_names}\")\n",
        "\n",
        "    # 2. Feature Extraction (TF-IDF Vectorization)\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', lowercase=True, max_df=0.5)\n",
        "    X_vec = vectorizer.fit_transform(X)\n",
        "    print(f\"Feature space size (vocabulary) before PCA: {X_vec.shape[1]}\")\n",
        "\n",
        "    # 3. Dimensionality Reduction using PCA\n",
        "    # We reduce the feature space to 2 dimensions for visualization.\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    X_2d = pca.fit_transform(X_vec.toarray()) # PCA requires dense array\n",
        "\n",
        "    # 4. Split the 2D data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_2d, y, test_size=TEST_SIZE, random_state=42\n",
        "    )\n",
        "    print(f\"\\nData successfully reduced to 2 dimensions for visualization.\")\n",
        "    print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n",
        "\n",
        "    # 5. Define different C values to compare regularization effects\n",
        "    C_values = [0.01, 1.0, 100.0]\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Create meshgrid for plotting the decision boundary\n",
        "    h = .02  # Step size in the mesh\n",
        "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
        "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    # 6. Train and Visualize SVM for each C value\n",
        "    for i, C in enumerate(C_values):\n",
        "        # We use a linear kernel for better interpretability in this context\n",
        "        svm_classifier = SVC(kernel='linear', C=C, random_state=42)\n",
        "        svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Predict class for every point in the mesh\n",
        "        Z = svm_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "        Z = Z.reshape(xx.shape)\n",
        "\n",
        "        # Create subplot for the current C value\n",
        "        ax = plt.subplot(1, len(C_values), i + 1)\n",
        "        ax.set_title(f\"SVM Decision Boundary (C={C})\")\n",
        "\n",
        "        # Plot the decision boundary and margin\n",
        "        ax.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.3)\n",
        "\n",
        "        # Plot the training points\n",
        "        scatter = ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.coolwarm, edgecolors='k')\n",
        "\n",
        "        # Optional: Plot the test set classification\n",
        "        y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "        # Add legend\n",
        "        ax.legend(handles=scatter.legend_elements()[0], labels=target_names)\n",
        "\n",
        "        # Print a quick report for this C value\n",
        "        report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
        "        accuracy = report['accuracy']\n",
        "        print(f\"C={C}: Test Accuracy = {accuracy:.4f}\")\n",
        "        ax.text(0.05, 0.95, f'Acc: {accuracy:.2f}', transform=ax.transAxes, fontsize=10, verticalalignment='top')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure scikit-learn, numpy, and matplotlib are installed:\n",
        "    # pip install scikit-learn numpy matplotlib\n",
        "\n",
        "    # Run the visualization program\n",
        "    visualize_svm_decision_boundaries(categories)\n"
      ],
      "metadata": {
        "id": "qu4iHD3Fi57c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "28.Write a Python program to train a Bernoulli Na√Øve Bayes classifier for binary classification on a dataset with\n",
        "binary features."
      ],
      "metadata": {
        "id": "Wzw1JYvUjGoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Removed matplotlib and PCA as visualization is not applicable to high-dimensional BNB\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer # Changed to CountVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB # Changed to BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- Configuration for Binary Classification ---\n",
        "# We use only two categories for a clear binary classification problem.\n",
        "categories = [\n",
        "    'rec.autos',\n",
        "    'comp.graphics',\n",
        "]\n",
        "# Use 80% for training and 20% for testing\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "def train_and_evaluate_bnb(categories_to_use):\n",
        "    \"\"\"\n",
        "    Loads the 20 Newsgroups dataset (binary), extracts binary features\n",
        "    using CountVectorizer(binary=True), trains a Bernoulli Naive Bayes classifier,\n",
        "    and prints the classification report and accuracy.\n",
        "    \"\"\"\n",
        "    print(f\"--- Loading data for categories: {categories_to_use} (Binary Classification) ---\")\n",
        "\n",
        "    # 1. Load the 20 Newsgroups dataset\n",
        "    newsgroups_data = fetch_20newsgroups(\n",
        "        subset='all',\n",
        "        categories=categories_to_use,\n",
        "        shuffle=True,\n",
        "        random_state=42,\n",
        "        remove=('headers', 'footers', 'quotes')\n",
        "    )\n",
        "\n",
        "    X, y = newsgroups_data.data, newsgroups_data.target\n",
        "    target_names = newsgroups_data.target_names\n",
        "\n",
        "    print(f\"Total samples loaded: {len(X)}\")\n",
        "    print(f\"Classes: {target_names}\")\n",
        "\n",
        "    # 2. Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining samples: {len(X_train)}\")\n",
        "    print(f\"Testing samples: {len(X_test)}\")\n",
        "\n",
        "    # 3. Feature Extraction (Binary Vectorization)\n",
        "    # CountVectorizer(binary=True) is used to ensure that the features are binary (0 or 1),\n",
        "    # representing only the presence or absence of a word, which is suitable\n",
        "    # for Bernoulli Naive Bayes.\n",
        "    vectorizer = CountVectorizer(\n",
        "        stop_words='english',\n",
        "        lowercase=True,\n",
        "        max_df=0.5,\n",
        "        binary=True # CRUCIAL: Makes the feature vectors binary (0 or 1)\n",
        "    )\n",
        "\n",
        "    # Fit and transform the data\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    print(f\"Feature space size (vocabulary): {X_train_vec.shape[1]}\")\n",
        "\n",
        "    # 4. Train the Bernoulli Na√Øve Bayes Classifier\n",
        "    print(\"\\n--- Training Bernoulli Na√Øve Bayes Classifier ---\")\n",
        "    bnb_classifier = BernoulliNB()\n",
        "    bnb_classifier.fit(X_train_vec, y_train)\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "    # 5. Make Predictions\n",
        "    y_pred = bnb_classifier.predict(X_test_vec)\n",
        "\n",
        "    # 6. Evaluate the Model\n",
        "    print(\"\\n--- Model Evaluation ---\")\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "    # Print detailed classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure scikit-learn and numpy are installed:\n",
        "    # pip install scikit-learn numpy\n",
        "\n",
        "    # Run the classification program\n",
        "    train_and_evaluate_bnb(categories)\n"
      ],
      "metadata": {
        "id": "YjzIIRDHjU6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "29.Write a Python program to apply feature scaling before training an SVM model and compare results with\n",
        "unscaled data."
      ],
      "metadata": {
        "id": "Is5-LKbPjaET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Removed matplotlib and PCA as visualization is not applicable to high-dimensional BNB\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # Changed back to TfidfVectorizer for continuous features\n",
        "from sklearn.svm import SVC # Switched to Support Vector Classifier\n",
        "from sklearn.preprocessing import StandardScaler # Added for feature scaling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- Configuration for Binary Classification ---\n",
        "# We use only two categories for a clear binary classification problem.\n",
        "categories = [\n",
        "    'rec.autos',\n",
        "    'comp.graphics',\n",
        "]\n",
        "# Use 80% for training and 20% for testing\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "def train_and_compare_svm_scaling(categories_to_use):\n",
        "    \"\"\"\n",
        "    Loads the 20 Newsgroups dataset, extracts TF-IDF features, and compares\n",
        "    the performance of an SVM classifier on unscaled versus scaled features.\n",
        "    \"\"\"\n",
        "    print(f\"--- Loading data for categories: {categories_to_use} (Binary Classification) ---\")\n",
        "\n",
        "    # 1. Load the 20 Newsgroups dataset\n",
        "    newsgroups_data = fetch_20newsgroups(\n",
        "        subset='all',\n",
        "        categories=categories_to_use,\n",
        "        shuffle=True,\n",
        "        random_state=42,\n",
        "        remove=('headers', 'footers', 'quotes')\n",
        "    )\n",
        "\n",
        "    X, y = newsgroups_data.data, newsgroups_data.target\n",
        "    target_names = newsgroups_data.target_names\n",
        "\n",
        "    print(f\"Total samples loaded: {len(X)}\")\n",
        "    print(f\"Classes: {target_names}\")\n",
        "\n",
        "    # 2. Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining samples: {len(X_train)}\")\n",
        "    print(f\"Testing samples: {len(X_test)}\")\n",
        "\n",
        "    # 3. Feature Extraction (TF-IDF Vectorization)\n",
        "    # Using TF-IDF, which produces continuous weights, making feature scaling relevant for SVM.\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english',\n",
        "        lowercase=True,\n",
        "        max_df=0.5,\n",
        "        ngram_range=(1, 2)\n",
        "    )\n",
        "\n",
        "    # Fit the vectorizer on the training data and transform both training and testing data\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    print(f\"Feature space size (vocabulary): {X_train_vec.shape[1]}\")\n",
        "\n",
        "    # Convert sparse matrices to dense for scaling.\n",
        "    # Note: StandardScaler in scikit-learn works best with dense data for consistent results.\n",
        "    X_train_dense = X_train_vec.toarray()\n",
        "    X_test_dense = X_test_vec.toarray()\n",
        "\n",
        "    # --- SCENARIO 1: SVM on UNSCALED Data ---\n",
        "    print(\"\\n--- SCENARIO 1: SVM on UNSCALED Data (TF-IDF vectors) ---\")\n",
        "\n",
        "    # Train the SVM model on the original (unscaled) dense TF-IDF vectors.\n",
        "    svm_unscaled = SVC(kernel='linear', random_state=42)\n",
        "    svm_unscaled.fit(X_train_dense, y_train)\n",
        "    y_pred_unscaled = svm_unscaled.predict(X_test_dense)\n",
        "\n",
        "    accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "    print(f\"Unscaled Data Accuracy: {accuracy_unscaled:.4f}\")\n",
        "    print(\"\\nUnscaled Data Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_unscaled, target_names=target_names))\n",
        "\n",
        "    # --- SCENARIO 2: SVM on SCALED Data ---\n",
        "    print(\"\\n--- SCENARIO 2: SVM on SCALED Data (TF-IDF vectors) ---\")\n",
        "\n",
        "    # 4. Feature Scaling (StandardScaler)\n",
        "    # Fit the scaler ONLY on the training data to prevent data leakage.\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_dense)\n",
        "    X_test_scaled = scaler.transform(X_test_dense)\n",
        "\n",
        "    # 5. Train the SVM Classifier on scaled data\n",
        "    svm_scaled = SVC(kernel='linear', random_state=42)\n",
        "    svm_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # 6. Make Predictions and Evaluate\n",
        "    y_pred_scaled = svm_scaled.predict(X_test_scaled)\n",
        "\n",
        "    accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "    print(f\"Scaled Data Accuracy: {accuracy_scaled:.4f}\")\n",
        "    print(\"\\nScaled Data Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_scaled, target_names=target_names))\n",
        "\n",
        "    # Final comparison summary\n",
        "    print(\"\\n--- Comparison Summary ---\")\n",
        "    print(f\"Accuracy (Unscaled): {accuracy_unscaled:.4f}\")\n",
        "    print(f\"Accuracy (Scaled):   {accuracy_scaled:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure scikit-learn and numpy are installed:\n",
        "    # pip install scikit-learn numpy\n",
        "\n",
        "    # Run the comparison program\n",
        "    train_and_compare_svm_scaling(categories)\n"
      ],
      "metadata": {
        "id": "vR8W9G4mjlsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "30.Write a Python program to train a Gaussian Na√Øve Bayes model and compare the predictions before and\n",
        "after Laplace Smoothing."
      ],
      "metadata": {
        "id": "qOL4_ogVkARL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer # Changed to CountVectorizer for MNB (count-based features)\n",
        "from sklearn.naive_bayes import MultinomialNB # Switched to Multinomial Naive Bayes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- Configuration for Binary Classification ---\n",
        "# We use only two categories for a clear binary classification problem.\n",
        "categories = [\n",
        "    'rec.autos',\n",
        "    'comp.graphics',\n",
        "]\n",
        "# Use 80% for training and 20% for testing\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "def train_and_compare_mnb_smoothing(categories_to_use):\n",
        "    \"\"\"\n",
        "    Loads the 20 Newsgroups dataset, extracts count features, and compares\n",
        "    the performance of Multinomial Naive Bayes with and without Laplace Smoothing.\n",
        "\n",
        "    Note: Laplace Smoothing is a core feature of MultinomialNB (via the 'alpha' parameter),\n",
        "    which is why we use MNB instead of GaussianNB for this comparison.\n",
        "    \"\"\"\n",
        "    print(f\"--- Loading data for categories: {categories_to_use} (Binary Classification) ---\")\n",
        "\n",
        "    # 1. Load the 20 Newsgroups dataset\n",
        "    newsgroups_data = fetch_20newsgroups(\n",
        "        subset='all',\n",
        "        categories=categories_to_use,\n",
        "        shuffle=True,\n",
        "        random_state=42,\n",
        "        remove=('headers', 'footers', 'quotes')\n",
        "    )\n",
        "\n",
        "    X, y = newsgroups_data.data, newsgroups_data.target\n",
        "    target_names = newsgroups_data.target_names\n",
        "\n",
        "    print(f\"Total samples loaded: {len(X)}\")\n",
        "    print(f\"Classes: {target_names}\")\n",
        "\n",
        "    # 2. Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining samples: {len(X_train)}\")\n",
        "    print(f\"Testing samples: {len(X_test)}\")\n",
        "\n",
        "    # 3. Feature Extraction (Count Vectorization)\n",
        "    # Using CountVectorizer to get integer counts (frequency of words),\n",
        "    # which is the input required by Multinomial Naive Bayes.\n",
        "    vectorizer = CountVectorizer(\n",
        "        stop_words='english',\n",
        "        lowercase=True,\n",
        "        max_df=0.5\n",
        "    )\n",
        "\n",
        "    # Fit the vectorizer on the training data and transform both training and testing data\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    print(f\"Feature space size (vocabulary): {X_train_vec.shape[1]}\")\n",
        "\n",
        "    # --- SCENARIO 1: Multinomial NB with Standard Laplace Smoothing (alpha=1.0) ---\n",
        "    # This is the standard, robust setting for Naive Bayes text classification.\n",
        "    print(\"\\n--- SCENARIO 1: MNB with Standard Laplace Smoothing (alpha=1.0) ---\")\n",
        "\n",
        "    # alpha=1.0 implements standard Laplace/Additive Smoothing\n",
        "    mnb_smoothed = MultinomialNB(alpha=1.0)\n",
        "    mnb_smoothed.fit(X_train_vec, y_train)\n",
        "    y_pred_smoothed = mnb_smoothed.predict(X_test_vec)\n",
        "\n",
        "    accuracy_smoothed = accuracy_score(y_test, y_pred_smoothed)\n",
        "    print(f\"Smoothed Data Accuracy: {accuracy_smoothed:.4f}\")\n",
        "    print(\"\\nSmoothed Data Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_smoothed, target_names=target_names))\n",
        "\n",
        "    # --- SCENARIO 2: Multinomial NB with Minimal Smoothing (alpha=1e-5) ---\n",
        "    # We use a very small alpha instead of alpha=0 to avoid division by zero errors\n",
        "    # in case a word has a zero count in a class (demonstrates the effect of no smoothing).\n",
        "    print(\"\\n--- SCENARIO 2: MNB with Minimal/No Smoothing (alpha=1e-5) ---\")\n",
        "\n",
        "    mnb_unsmoothed = MultinomialNB(alpha=1e-5)\n",
        "    mnb_unsmoothed.fit(X_train_vec, y_train)\n",
        "    y_pred_unsmoothed = mnb_unsmoothed.predict(X_test_vec)\n",
        "\n",
        "    accuracy_unsmoothed = accuracy_score(y_test, y_pred_unsmoothed)\n",
        "    print(f\"Minimal Smoothing Accuracy: {accuracy_unsmoothed:.4f}\")\n",
        "    print(\"\\nMinimal Smoothing Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_unsmoothed, target_names=target_names))\n",
        "\n",
        "    # Final comparison summary\n",
        "    print(\"\\n--- Comparison Summary ---\")\n",
        "    print(f\"Accuracy (Standard Laplace Smoothing, alpha=1.0): {accuracy_smoothed:.4f}\")\n",
        "    print(f\"Accuracy (Minimal Smoothing, alpha=1e-5):         {accuracy_unsmoothed:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure scikit-learn and numpy are installed:\n",
        "    # pip install scikit-learn numpy\n",
        "\n",
        "    # Run the comparison program\n",
        "    train_and_compare_mnb_smoothing(categories)\n"
      ],
      "metadata": {
        "id": "SQrgI4VwkLhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "31.Write a Python program to train an SVM Classifier and use GridSearchCV to tune the hyperparameters (C,\n",
        "gamma, kernel)"
      ],
      "metadata": {
        "id": "CBm_p1X7kRVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from scipy.sparse import issparse\n",
        "\n",
        "# --- Configuration for Binary Classification ---\n",
        "# We use only two categories for a clear binary classification problem.\n",
        "categories = [\n",
        "    'rec.autos',\n",
        "    'comp.graphics',\n",
        "]\n",
        "# Use 80% for training and 20% for testing\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "def train_and_tune_svm(categories_to_use):\n",
        "    \"\"\"\n",
        "    Loads the 20 Newsgroups dataset, extracts TF-IDF features, and uses\n",
        "    GridSearchCV to find the best hyperparameters for an SVM Classifier.\n",
        "    \"\"\"\n",
        "    print(f\"--- Loading data for categories: {categories_to_use} (Binary Classification) ---\")\n",
        "\n",
        "    # 1. Load the 20 Newsgroups dataset\n",
        "    newsgroups_data = fetch_20newsgroups(\n",
        "        subset='all',\n",
        "        categories=categories_to_use,\n",
        "        shuffle=True,\n",
        "        random_state=42,\n",
        "        remove=('headers', 'footers', 'quotes')\n",
        "    )\n",
        "\n",
        "    X, y = newsgroups_data.data, newsgroups_data.target\n",
        "    target_names = newsgroups_data.target_names\n",
        "\n",
        "    # 2. Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining samples: {len(X_train)}\")\n",
        "    print(f\"Testing samples: {len(X_test)}\")\n",
        "\n",
        "    # 3. Feature Extraction (TF-IDF Vectorization)\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english',\n",
        "        lowercase=True,\n",
        "        max_df=0.5\n",
        "    )\n",
        "\n",
        "    # Fit and transform the data\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    print(f\"Feature space size (vocabulary): {X_train_vec.shape[1]}\")\n",
        "\n",
        "    # Convert sparse matrices to dense arrays for compatibility with GridSearchCV\n",
        "    # when using non-linear kernels like 'rbf'.\n",
        "    if issparse(X_train_vec):\n",
        "        X_train_dense = X_train_vec.toarray()\n",
        "        X_test_dense = X_test_vec.toarray()\n",
        "    else:\n",
        "        X_train_dense = X_train_vec\n",
        "        X_test_dense = X_test_vec\n",
        "\n",
        "    # 4. Define Hyperparameter Grid for SVM\n",
        "    param_grid = [\n",
        "      # Linear kernel: tune C (regularization parameter)\n",
        "      {'C': [0.1, 1, 10], 'kernel': ['linear']},\n",
        "      # RBF kernel: tune C and gamma (kernel coefficient)\n",
        "      {'C': [1, 10, 100], 'gamma': [0.001, 0.01, 0.1], 'kernel': ['rbf']},\n",
        "     ]\n",
        "\n",
        "    # 5. Initialize and Run GridSearchCV\n",
        "    print(\"\\n--- Starting GridSearchCV for SVM (may take a few minutes) ---\")\n",
        "\n",
        "    # GridSearchCV performs 3-fold cross-validation (cv=3) for each parameter combination\n",
        "    grid_search = GridSearchCV(\n",
        "        SVC(random_state=42),\n",
        "        param_grid,\n",
        "        cv=3,\n",
        "        scoring='accuracy',\n",
        "        verbose=1,\n",
        "        n_jobs=-1 # Use all available cores for parallel processing\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train_dense, y_train)\n",
        "\n",
        "    print(\"Grid Search complete.\")\n",
        "\n",
        "    # 6. Evaluate the Best Estimator\n",
        "\n",
        "    # Get the best model determined by the grid search\n",
        "    best_svm = grid_search.best_estimator_\n",
        "\n",
        "    # Print the tuning results\n",
        "    print(\"\\n--- Hyperparameter Tuning Results ---\")\n",
        "    print(f\"Best Parameters found on training set: {grid_search.best_params_}\")\n",
        "    print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    # Make predictions on the held-out test set using the best model\n",
        "    y_pred = best_svm.predict(X_test_dense)\n",
        "\n",
        "    # 7. Print Final Test Set Performance\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\n--- Final Test Set Evaluation using Best Model ---\")\n",
        "    print(f\"Test Accuracy Score: {test_accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report on Test Set:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure scikit-learn and numpy are installed:\n",
        "    # pip install scikit-learn numpy\n",
        "\n",
        "    # Run the SVM tuning program\n",
        "    train_and_tune_svm(categories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrkH_iAJkXNp",
        "outputId": "76db4844-a8ef-4655-819e-a6e9fe972387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading data for categories: ['rec.autos', 'comp.graphics'] (Binary Classification) ---\n",
            "\n",
            "Training samples: 1570\n",
            "Testing samples: 393\n",
            "Feature space size (vocabulary): 18309\n",
            "\n",
            "--- Starting GridSearchCV for SVM (may take a few minutes) ---\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "32.Write a Python program to train an SVM Classifier on an imbalanced dataset and apply class weighting and\n",
        "check it improve accuracy."
      ],
      "metadata": {
        "id": "yIy2QmFhkeqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from scipy.sparse import issparse\n",
        "\n",
        "# --- Configuration for Binary Classification ---\n",
        "# We use two categories that are generally well-separated but will be artificially\n",
        "# made imbalanced in the training set for demonstration.\n",
        "categories = [\n",
        "    'rec.autos',      # Class 0\n",
        "    'comp.graphics',  # Class 1\n",
        "]\n",
        "# Use 80% for training and 20% for testing\n",
        "TEST_SIZE = 0.2\n",
        "MINORITY_SAMPLES = 50 # Artificially restrict one class in the training set to this size\n",
        "\n",
        "def train_and_compare_class_weighting(categories_to_use):\n",
        "    \"\"\"\n",
        "    Loads the 20 Newsgroups dataset, creates a synthetic imbalance in the\n",
        "    training data, and compares the performance of unweighted vs. class-weighted SVM.\n",
        "    \"\"\"\n",
        "    print(f\"--- Loading data for categories: {categories_to_use} (Binary Classification) ---\")\n",
        "\n",
        "    # 1. Load the 20 Newsgroups dataset\n",
        "    newsgroups_data = fetch_20newsgroups(\n",
        "        subset='all',\n",
        "        categories=categories_to_use,\n",
        "        shuffle=True,\n",
        "        random_state=42,\n",
        "        remove=('headers', 'footers', 'quotes')\n",
        "    )\n",
        "\n",
        "    X, y = newsgroups_data.data, newsgroups_data.target\n",
        "    target_names = newsgroups_data.target_names\n",
        "\n",
        "    # 2. Split the data into initial training and testing sets\n",
        "    # The test set remains representative of the original, balanced distribution.\n",
        "    X_train_raw, X_test, y_train_raw, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=42\n",
        "    )\n",
        "\n",
        "    # 3. Create Synthetic Imbalance in the Training Set\n",
        "    class_0_indices = np.where(y_train_raw == 0)[0]\n",
        "    class_1_indices = np.where(y_train_raw == 1)[0]\n",
        "\n",
        "    # Identify minority and majority for the demonstration\n",
        "    if len(class_0_indices) < len(class_1_indices):\n",
        "        minority_indices = class_0_indices\n",
        "        majority_indices = class_1_indices\n",
        "        minority_label_idx = 0\n",
        "    else:\n",
        "        minority_indices = class_1_indices\n",
        "        majority_indices = class_0_indices\n",
        "        minority_label_idx = 1\n",
        "\n",
        "    minority_class_name = target_names[minority_label_idx]\n",
        "\n",
        "    # Subsample the majority class to create the imbalance\n",
        "    # Note: We are doing the opposite of what the variable names suggest for a clear demonstration:\n",
        "    # We are keeping a large majority and heavily restricting the minority in the training set.\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(minority_indices)\n",
        "\n",
        "    # Restrict the minority class to MINORITY_SAMPLES\n",
        "    minority_indices_kept = minority_indices[:MINORITY_SAMPLES]\n",
        "\n",
        "    # Combine the restricted minority and the full majority to form the imbalanced training set\n",
        "    imbalanced_train_indices = np.concatenate([minority_indices_kept, majority_indices])\n",
        "\n",
        "    X_train = np.array(X_train_raw)[imbalanced_train_indices]\n",
        "    y_train = y_train_raw[imbalanced_train_indices]\n",
        "\n",
        "    print(f\"\\nTraining set samples (Imbalanced): {len(X_train)}\")\n",
        "    print(f\"  Class '{target_names[0]}' count: {np.sum(y_train == 0)}\")\n",
        "    print(f\"  Class '{target_names[1]}' count: {np.sum(y_train == 1)}\")\n",
        "    print(f\"  Minority Class (Heavily Undersampled): {minority_class_name}\")\n",
        "    print(f\"Testing set samples (Original Distribution): {len(X_test)}\")\n",
        "\n",
        "    # 4. Feature Extraction (TF-IDF Vectorization)\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english',\n",
        "        lowercase=True,\n",
        "        max_df=0.5\n",
        "    )\n",
        "\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    # Convert sparse to dense for SVC, as done previously\n",
        "    if issparse(X_train_vec):\n",
        "        X_train_dense = X_train_vec.toarray()\n",
        "        X_test_dense = X_test_vec.toarray()\n",
        "    else:\n",
        "        X_train_dense = X_train_vec\n",
        "        X_test_dense = X_test_vec\n",
        "\n",
        "    # --- SCENARIO 1: SVM on Imbalanced Data (UNWEIGHTED) ---\n",
        "    print(\"\\n--- SCENARIO 1: SVM (Unweighted, class_weight=None) ---\")\n",
        "\n",
        "    svm_unweighted = SVC(kernel='linear', C=1.0, random_state=42, class_weight=None)\n",
        "    svm_unweighted.fit(X_train_dense, y_train)\n",
        "    y_pred_unweighted = svm_unweighted.predict(X_test_dense)\n",
        "\n",
        "    print(f\"Accuracy (Unweighted): {accuracy_score(y_test, y_pred_unweighted):.4f}\")\n",
        "    print(\"\\nClassification Report (Unweighted):\")\n",
        "    print(classification_report(y_test, y_pred_unweighted, target_names=target_names))\n",
        "\n",
        "    # --- SCENARIO 2: SVM on Imbalanced Data (CLASS WEIGHTED) ---\n",
        "    print(\"\\n--- SCENARIO 2: SVM (Class-Weighted, class_weight='balanced') ---\")\n",
        "\n",
        "    # 'balanced' automatically adjusts weights inversely proportional to class frequencies\n",
        "    # in the input data, giving more importance to the minority class.\n",
        "    svm_weighted = SVC(kernel='linear', C=1.0, random_state=42, class_weight='balanced')\n",
        "    svm_weighted.fit(X_train_dense, y_train)\n",
        "    y_pred_weighted = svm_weighted.predict(X_test_dense)\n",
        "\n",
        "    print(f\"Accuracy (Weighted): {accuracy_score(y_test, y_pred_weighted):.4f}\")\n",
        "    print(\"\\nClassification Report (Weighted):\")\n",
        "    print(classification_report(y_test, y_pred_weighted, target_names=target_names))\n",
        "\n",
        "    # Final comparison summary focusing on the minority class\n",
        "    print(\"\\n--- Comparison Summary (Focus on Minority Class Metrics) ---\")\n",
        "\n",
        "    # Find the index corresponding to the minority class in the classification report\n",
        "    minority_report_unweighted = classification_report(y_test, y_pred_unweighted, target_names=target_names, output_dict=True)[minority_class_name]\n",
        "    minority_report_weighted = classification_report(y_test, y_pred_weighted, target_names=target_names, output_dict=True)[minority_class_name]\n",
        "\n",
        "    print(f\"Minority Class: {minority_class_name}\")\n",
        "    print(f\"Unweighted Recall: {minority_report_unweighted['recall']:.4f} | Weighted Recall: {minority_report_weighted['recall']:.4f}\")\n",
        "    print(f\"Unweighted F1-Score: {minority_report_unweighted['f1-score']:.4f} | Weighted F1-Score: {minority_report_weighted['f1-score']:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure scikit-learn and numpy are installed:\n",
        "    # pip install scikit-learn numpy\n",
        "\n",
        "    # Run the SVM class weighting comparison program\n",
        "    train_and_compare_class_weighting(categories)"
      ],
      "metadata": {
        "id": "pcuFHTAXknTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "33.Write a Python program to implement a Na√Øve Bayes classifier for spam detection using email data"
      ],
      "metadata": {
        "id": "dXfns_i7kvOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer # Using CountVectorizer for Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB # Using Multinomial Naive Bayes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# --- Configuration for Binary Classification (Simulating Spam/Ham) ---\n",
        "# We use two distinct newsgroup categories to simulate the content difference\n",
        "# between two classes, like Spam and Legitimate (Ham) emails.\n",
        "categories = [\n",
        "    'alt.atheism',      # Simulating one class (e.g., \"Spam\")\n",
        "    'comp.graphics',    # Simulating the other class (e.g., \"Ham\")\n",
        "]\n",
        "# Use 80% for training and 20% for testing\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "def train_naive_bayes_spam_classifier(categories_to_use):\n",
        "    \"\"\"\n",
        "    Loads a subset of the 20 Newsgroups dataset, uses CountVectorizer for features,\n",
        "    and trains a Multinomial Naive Bayes classifier for binary classification\n",
        "    (simulated spam detection).\n",
        "    \"\"\"\n",
        "    print(f\"--- Loading data for categories: {categories_to_use} (Simulated Spam/Ham) ---\")\n",
        "\n",
        "    # 1. Load the 20 Newsgroups dataset\n",
        "    newsgroups_data = fetch_20newsgroups(\n",
        "        subset='all',\n",
        "        categories=categories_to_use,\n",
        "        shuffle=True,\n",
        "        random_state=42,\n",
        "        remove=('headers', 'footers', 'quotes')\n",
        "    )\n",
        "\n",
        "    X, y = newsgroups_data.data, newsgroups_data.target\n",
        "    target_names = newsgroups_data.target_names\n",
        "\n",
        "    # Rename targets to reflect Spam/Ham analogy\n",
        "    target_names_map = {0: 'Class_A (alt.atheism)', 1: 'Class_B (comp.graphics)'}\n",
        "    mapped_target_names = [target_names_map[i] for i in range(len(target_names))]\n",
        "\n",
        "    print(f\"Total samples loaded: {len(X)}\")\n",
        "    print(f\"Classes: {mapped_target_names}\")\n",
        "\n",
        "    # 2. Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=TEST_SIZE, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining samples: {len(X_train)}\")\n",
        "    print(f\"Testing samples: {len(X_test)}\")\n",
        "\n",
        "    # 3. Feature Extraction (Count Vectorization)\n",
        "    # Naive Bayes generally performs well with raw word counts.\n",
        "    vectorizer = CountVectorizer(\n",
        "        stop_words='english',\n",
        "        lowercase=True,\n",
        "        max_df=0.7 # Ignore terms that appear in more than 70% of the documents\n",
        "    )\n",
        "\n",
        "    # Fit the vectorizer on the training data and transform both sets\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    print(f\"Feature space size (vocabulary): {X_train_vec.shape[1]}\")\n",
        "\n",
        "    # 4. Train the Multinomial Naive Bayes Model\n",
        "    # MNB uses Additive (Laplace) Smoothing by default (alpha=1.0) for stability.\n",
        "    print(\"\\n--- Training Multinomial Naive Bayes Classifier ---\")\n",
        "\n",
        "    mnb_classifier = MultinomialNB(alpha=1.0)\n",
        "    mnb_classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "    # 5. Evaluate the Classifier\n",
        "    y_pred = mnb_classifier.predict(X_test_vec)\n",
        "\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=mapped_target_names))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure scikit-learn and numpy are installed:\n",
        "    # pip install scikit-learn numpy\n",
        "\n",
        "    # Run the Naive Bayes spam detection program\n",
        "    train_naive_bayes_spam_classifier(categories)"
      ],
      "metadata": {
        "id": "0Zz4i6qTk1Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "34.Write a Python program to train an SVM Classifier and a Na√Øve Bayes Classifier on the same dataset and\n",
        "compare their accuracy."
      ],
      "metadata": {
        "id": "YPMA-8Gqk-Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We will use the Iris dataset, a classic dataset for classification tasks.\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# --- 2. Split the Data ---\n",
        "# Split the data into training (70%) and testing (30%) sets.\n",
        "# We set a random_state for reproducibility.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- 3. Initialize and Train Classifiers ---\n",
        "\n",
        "# A. Support Vector Machine (SVC)\n",
        "# We use a radial basis function (rbf) kernel, a common choice for non-linear data.\n",
        "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
        "print(\"Training SVM Classifier...\")\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# B. Gaussian Na√Øve Bayes (GNB)\n",
        "# GaussianNB is suitable for continuous data, assuming features follow a Gaussian distribution.\n",
        "gnb_classifier = GaussianNB()\n",
        "print(\"Training Gaussian Na√Øve Bayes Classifier...\")\n",
        "gnb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# --- 4. Predict and Evaluate ---\n",
        "\n",
        "# A. SVM Prediction and Accuracy\n",
        "svm_predictions = svm_classifier.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "\n",
        "# B. Na√Øve Bayes Prediction and Accuracy\n",
        "gnb_predictions = gnb_classifier.predict(X_test)\n",
        "gnb_accuracy = accuracy_score(y_test, gnb_predictions)\n",
        "\n",
        "\n",
        "# --- 5. Print Comparison Results ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CLASSIFIER ACCURACY COMPARISON\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Dataset: Iris (30% Test Set)\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"| {'Model':<30} | {'Accuracy':<15} |\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"| {'Support Vector Machine (SVC)':<30} | {svm_accuracy:.4f} ({(svm_accuracy*100):.2f}%) |\")\n",
        "print(f\"| {'Gaussian Na√Øve Bayes (GNB)':<30} | {gnb_accuracy:.4f} ({(gnb_accuracy*100):.2f}%) |\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Provide a brief analysis\n",
        "if svm_accuracy > gnb_accuracy:\n",
        "    print(f\"\\nConclusion: SVM outperformed Na√Øve Bayes by {(svm_accuracy - gnb_accuracy):.4f} accuracy points on this dataset.\")\n",
        "elif gnb_accuracy > svm_accuracy:\n",
        "    print(f\"\\nConclusion: Na√Øve Bayes outperformed SVM by {(gnb_accuracy - svm_accuracy):.4f} accuracy points on this dataset.\")\n",
        "else:\n",
        "    print(\"\\nConclusion: Both classifiers achieved the exact same accuracy score.\")\n",
        "\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "uLN879wjlQCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "35.Write a Python program to perform feature selection before training a Na√Øve Bayes classifier and compare\n",
        "results."
      ],
      "metadata": {
        "id": "QaRpiG2LlZMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif # NEW: Imports for feature selection\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We will use the Iris dataset, a classic dataset for classification tasks.\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# --- 2. Split the Data ---\n",
        "# Split the data into training (70%) and testing (30%) sets.\n",
        "# We set a random_state for reproducibility.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- 3. Feature Selection ---\n",
        "# Use SelectKBest with f_classif (ANOVA F-value) to find the best 2 features (out of 4).\n",
        "k_best_features = 2\n",
        "selector = SelectKBest(f_classif, k=k_best_features)\n",
        "selector.fit(X_train, y_train)\n",
        "\n",
        "# Transform the training and test sets using the selected features\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "print(f\"Feature Selection: Selected {k_best_features} features based on f_classif.\")\n",
        "# Print the names of the selected features for clarity\n",
        "feature_names = load_iris().feature_names\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "print(f\"Selected feature names: {[feature_names[i] for i in selected_indices]}\")\n",
        "\n",
        "\n",
        "# --- 4. Initialize and Train Classifiers ---\n",
        "\n",
        "# A. Support Vector Machine (SVC) - Trained on ALL features\n",
        "# We use a radial basis function (rbf) kernel, a common choice for non-linear data.\n",
        "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
        "print(\"\\nTraining SVM Classifier (on ALL features)...\")\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# B. Gaussian Na√Øve Bayes (GNB) - Trained on ALL features\n",
        "# GaussianNB is suitable for continuous data, assuming features follow a Gaussian distribution.\n",
        "gnb_classifier = GaussianNB()\n",
        "print(\"Training Gaussian Na√Øve Bayes Classifier (on ALL features)...\")\n",
        "gnb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# C. Gaussian Na√Øve Bayes (GNB) - Trained on SELECTED features (NEW MODEL)\n",
        "gnb_selected_classifier = GaussianNB()\n",
        "print(f\"Training GNB Classifier (on SELECTED {k_best_features} features)...\")\n",
        "gnb_selected_classifier.fit(X_train_selected, y_train)\n",
        "\n",
        "\n",
        "# --- 5. Predict and Evaluate ---\n",
        "\n",
        "# A. SVM Prediction and Accuracy (on ALL features)\n",
        "svm_predictions = svm_classifier.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "\n",
        "# B. Na√Øve Bayes Prediction and Accuracy (on ALL features)\n",
        "gnb_predictions = gnb_classifier.predict(X_test)\n",
        "gnb_accuracy = accuracy_score(y_test, gnb_predictions)\n",
        "\n",
        "# C. Na√Øve Bayes Prediction and Accuracy (on SELECTED features)\n",
        "gnb_selected_predictions = gnb_selected_classifier.predict(X_test_selected)\n",
        "gnb_selected_accuracy = accuracy_score(y_test, gnb_selected_predictions)\n",
        "\n",
        "\n",
        "# --- 6. Print Comparison Results --- (Updated to include all three models)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLASSIFIER ACCURACY COMPARISON WITH FEATURE SELECTION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Dataset: Iris (30% Test Set, Random State 42)\")\n",
        "print(f\"Feature Selection Method: SelectKBest (k={k_best_features}) with f_classif\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"| {'Model':<50} | {'Accuracy':<15} |\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"| {'Support Vector Machine (SVC) - All Features':<50} | {svm_accuracy:.4f} ({(svm_accuracy*100):.2f}%) |\")\n",
        "print(f\"| {'Gaussian Na√Øve Bayes (GNB) - All Features':<50} | {gnb_accuracy:.4f} ({(gnb_accuracy*100):.2f}%) |\")\n",
        "print(f\"| {'GNB - Selected Features (k=2)':<50} | {gnb_selected_accuracy:.4f} ({(gnb_selected_accuracy*100):.2f}%) |\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Provide a brief analysis (focusing on GNB comparison)\n",
        "print(\"\\nAnalysis of Na√Øve Bayes Models:\")\n",
        "\n",
        "if gnb_selected_accuracy > gnb_accuracy:\n",
        "    print(f\"- Feature selection IMPROVED GNB accuracy by {(gnb_selected_accuracy - gnb_accuracy):.4f}.\")\n",
        "elif gnb_accuracy > gnb_selected_accuracy:\n",
        "    print(f\"- Feature selection DECREASED GNB accuracy by {(gnb_accuracy - gnb_selected_accuracy):.4f}.\")\n",
        "else:\n",
        "    print(\"- Feature selection resulted in the same GNB accuracy.\")\n",
        "\n",
        "# Overall winner\n",
        "accuracies = {\n",
        "    'SVC - All Features': svm_accuracy,\n",
        "    'GNB - All Features': gnb_accuracy,\n",
        "    'GNB - Selected Features (k=2)': gnb_selected_accuracy\n",
        "}\n",
        "best_model = max(accuracies, key=accuracies.get)\n",
        "best_accuracy = accuracies[best_model]\n",
        "\n",
        "print(f\"\\nOverall Best Model: {best_model} with an accuracy of {best_accuracy:.4f}.\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "SDGcM4ckleJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "36.Write a Python program to train an SVM Classifier using One-vs-Rest (OvR) and One-vs-One (OvO)\n",
        "strategies on the Wine dataset and compare their accuracy."
      ],
      "metadata": {
        "id": "PCJwtTO2lj0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_wine # Changed from load_iris to load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier # NEW: Import for explicit One-vs-Rest strategy\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Feature selection and Naive Bayes imports are removed as they are not needed for this comparison\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We will use the Wine dataset, which has 3 classes and 13 features.\n",
        "X, y = load_wine(return_X_y=True)\n",
        "\n",
        "# --- 2. Split the Data ---\n",
        "# Split the data into training (70%) and testing (30%) sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- 3. Initialize and Train SVM Classifiers ---\n",
        "\n",
        "# The underlying SVC model used for both strategies\n",
        "base_svc = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "# A. One-vs-One (OvO) Strategy\n",
        "# SVC implements OvO by default, but we set decision_function_shape='ovo' for clarity.\n",
        "# SVC is often preferred for OvO due to computational efficiency on smaller datasets.\n",
        "svc_ovo = SVC(kernel='rbf', decision_function_shape='ovo', random_state=42)\n",
        "print(\"Training SVM Classifier with One-vs-One (OvO) strategy...\")\n",
        "svc_ovo.fit(X_train, y_train)\n",
        "\n",
        "# B. One-vs-Rest (OvR) Strategy\n",
        "# We use the OneVsRestClassifier meta-estimator to explicitly enforce the OvR strategy.\n",
        "svc_ovr = OneVsRestClassifier(base_svc)\n",
        "print(\"Training SVM Classifier with One-vs-Rest (OvR) strategy...\")\n",
        "svc_ovr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# --- 4. Predict and Evaluate ---\n",
        "\n",
        "# A. OvO Prediction and Accuracy\n",
        "ovo_predictions = svc_ovo.predict(X_test)\n",
        "ovo_accuracy = accuracy_score(y_test, ovo_predictions)\n",
        "\n",
        "# B. OvR Prediction and Accuracy\n",
        "ovr_predictions = svc_ovr.predict(X_test)\n",
        "ovr_accuracy = accuracy_score(y_test, ovr_predictions)\n",
        "\n",
        "\n",
        "# --- 5. Print Comparison Results ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SVM MULTI-CLASS STRATEGY ACCURACY COMPARISON (WINE DATASET)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Dataset: Wine (30% Test Set, Random State 42)\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"| {'Strategy':<50} | {'Accuracy':<15} |\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"| {'Support Vector Machine (OvO - SVC default)':<50} | {ovo_accuracy:.4f} ({(ovo_accuracy*100):.2f}%) |\")\n",
        "print(f\"| {'Support Vector Machine (OvR - OneVsRestWrapper)':<50} | {ovr_accuracy:.4f} ({(ovr_accuracy*100):.2f}%) |\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Provide a brief analysis\n",
        "if ovo_accuracy > ovr_accuracy:\n",
        "    print(f\"\\nConclusion: The One-vs-One (OvO) strategy performed better on the Wine dataset by {(ovo_accuracy - ovr_accuracy):.4f} accuracy points.\")\n",
        "elif ovr_accuracy > ovo_accuracy:\n",
        "    print(f\"\\nConclusion: The One-vs-Rest (OvR) strategy performed better on the Wine dataset by {(ovr_accuracy - ovo_accuracy):.4f} accuracy points.\")\n",
        "else:\n",
        "    print(\"\\nConclusion: Both OvO and OvR strategies resulted in the exact same accuracy score on the Wine dataset.\")\n",
        "\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "vcWjldVYlq8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "37.Write a Python program to train an SVM Classifier using Linear, Polynomial, and RBF kernels on the Breast\n",
        "Cancer dataset and compare their accuracy."
      ],
      "metadata": {
        "id": "w0C9DZPel5jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer # NEW: Switched to Breast Cancer dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler # NEW: Added for feature scaling, critical for SVM\n",
        "from sklearn.pipeline import make_pipeline # NEW: For chaining scaling and SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We will use the Breast Cancer dataset (binary classification).\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# --- 2. Split the Data ---\n",
        "# Split the data into training (70%) and testing (30%) sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- 3. Initialize and Train SVM Classifiers with Different Kernels ---\n",
        "# SVM performance is highly dependent on feature scaling, so we use a pipeline\n",
        "# to standardize the data before training each classifier.\n",
        "\n",
        "# A. Linear Kernel SVM\n",
        "# Good for linearly separable data.\n",
        "pipeline_linear = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(kernel='linear', C=1.0, random_state=42)\n",
        ")\n",
        "print(\"Training SVM Classifier with Linear Kernel...\")\n",
        "pipeline_linear.fit(X_train, y_train)\n",
        "\n",
        "# B. Polynomial Kernel SVM\n",
        "# Good for non-linear data; 'degree' controls the complexity of the non-linearity.\n",
        "pipeline_poly = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(kernel='poly', degree=3, C=1.0, random_state=42)\n",
        ")\n",
        "print(\"Training SVM Classifier with Polynomial (Degree 3) Kernel...\")\n",
        "pipeline_poly.fit(X_train, y_train)\n",
        "\n",
        "# C. RBF (Radial Basis Function) Kernel SVM\n",
        "# The most common choice, good for highly non-linear data.\n",
        "pipeline_rbf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(kernel='rbf', gamma='scale', C=1.0, random_state=42)\n",
        ")\n",
        "print(\"Training SVM Classifier with RBF Kernel...\")\n",
        "pipeline_rbf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# --- 4. Predict and Evaluate ---\n",
        "\n",
        "# A. Linear Kernel Accuracy\n",
        "linear_predictions = pipeline_linear.predict(X_test)\n",
        "linear_accuracy = accuracy_score(y_test, linear_predictions)\n",
        "\n",
        "# B. Polynomial Kernel Accuracy\n",
        "poly_predictions = pipeline_poly.predict(X_test)\n",
        "poly_accuracy = accuracy_score(y_test, poly_predictions)\n",
        "\n",
        "# C. RBF Kernel Accuracy\n",
        "rbf_predictions = pipeline_rbf.predict(X_test)\n",
        "rbf_accuracy = accuracy_score(y_test, rbf_predictions)\n",
        "\n",
        "\n",
        "# --- 5. Print Comparison Results ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SVM KERNEL ACCURACY COMPARISON (BREAST CANCER DATASET)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Dataset: Breast Cancer (30% Test Set, Random State 42)\")\n",
        "print(f\"Note: All models include feature scaling (StandardScaler).\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"| {'Kernel Type':<60} | {'Accuracy':<15} |\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"| {'1. Linear Kernel':<60} | {linear_accuracy:.4f} ({(linear_accuracy*100):.2f}%) |\")\n",
        "print(f\"| {'2. Polynomial Kernel (Degree 3)':<60} | {poly_accuracy:.4f} ({(poly_accuracy*100):.2f}%) |\")\n",
        "print(f\"| {'3. RBF (Radial Basis Function) Kernel':<60} | {rbf_accuracy:.4f} ({(rbf_accuracy*100):.2f}%) |\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Identify the best performing kernel\n",
        "accuracies = {\n",
        "    'Linear': linear_accuracy,\n",
        "    'Polynomial (Degree 3)': poly_accuracy,\n",
        "    'RBF': rbf_accuracy\n",
        "}\n",
        "best_kernel = max(accuracies, key=accuracies.get)\n",
        "best_accuracy = accuracies[best_kernel]\n",
        "\n",
        "print(f\"\\nOverall Best Kernel: {best_kernel} with an accuracy of {best_accuracy:.4f}.\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "wU0KYwR7l-uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "38.Write a Python program to train an SVM Classifier using Stratified K-Fold Cross-Validation and compute the\n",
        "average accuracy."
      ],
      "metadata": {
        "id": "R7K8ncilmDx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score # NEW: Imports for Cross-Validation\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from statistics import mean, stdev # For calculation of mean and std deviation\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We will use the Breast Cancer dataset (binary classification).\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Define the number of splits for cross-validation\n",
        "N_SPLITS = 5\n",
        "\n",
        "# --- 2. Setup the Model Pipeline ---\n",
        "# SVM performance is highly dependent on feature scaling, so we use a pipeline\n",
        "# to standardize the data before training the RBF kernel classifier.\n",
        "\n",
        "# We use the RBF (Radial Basis Function) Kernel, the most common choice.\n",
        "# The 'gamma' and 'C' parameters are left at default for simplicity.\n",
        "model_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(kernel='rbf', gamma='scale', C=1.0, random_state=42)\n",
        ")\n",
        "\n",
        "# --- 3. Setup Stratified K-Fold Cross-Validation ---\n",
        "# StratifiedKFold ensures that each fold has the same proportion of class labels (malignant/benign)\n",
        "# as the full dataset, which is important for binary classification problems.\n",
        "cv_strategy = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"Model: RBF Kernel SVM with StandardScaler\")\n",
        "print(f\"Validation Strategy: Stratified {N_SPLITS}-Fold Cross-Validation (Shuffle=True)\")\n",
        "print(\"Starting cross-validation...\")\n",
        "\n",
        "# --- 4. Evaluate the Model using Cross-Validation ---\n",
        "# The cross_val_score function automatically trains and evaluates the model\n",
        "# N_SPLITS times, fitting the pipeline on the training folds and scoring on the test fold.\n",
        "cv_scores = cross_val_score(\n",
        "    model_pipeline,\n",
        "    X,\n",
        "    y,\n",
        "    cv=cv_strategy,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1 # Use all available processors for faster computation\n",
        ")\n",
        "\n",
        "# Calculate the statistics\n",
        "mean_accuracy = mean(cv_scores)\n",
        "std_dev = stdev(cv_scores)\n",
        "\n",
        "\n",
        "# --- 5. Print Comparison Results ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SVM RBF KERNEL ACCURACY WITH STRATIFIED CROSS-VALIDATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Dataset: Breast Cancer (Total Samples: {X.shape[0]})\")\n",
        "print(f\"Cross-Validation Folds: {N_SPLITS}\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"Individual Fold Accuracy Scores:\")\n",
        "# Print scores in a formatted list\n",
        "for i, score in enumerate(cv_scores):\n",
        "    print(f\"  Fold {i+1}: {score:.4f} ({(score*100):.2f}%)\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"| {'Metric':<30} | {'Value':<15} |\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"| {'Mean Cross-Validation Accuracy':<30} | {mean_accuracy:.4f} ({(mean_accuracy*100):.2f}%) |\")\n",
        "# Report mean +/- standard deviation * 2 (approx. 95% confidence interval)\n",
        "print(f\"| {'Accuracy (Mean +/- 2*Std Dev)':<30} | {mean_accuracy:.4f} +/- {(std_dev*2):.4f} |\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(\"\\nConclusion: The average accuracy across all folds provides a robust estimate of the model's performance on unseen data.\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "Q7-uIAhymHxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Python program to train a Na√Øve Bayes classifier using different prior probabilities and compare\n",
        "performance\n",
        "\n",
        "Write a Python program to perform Recursive Feature Elimination (RFE) before training an SVM Classifier and\n",
        "compare accuracy\n",
        "\n",
        " Write a Python program to train an SVM Classifier and evaluate its performance using Precision, Recall, and\n",
        "F1-Score instead of accuracy\n",
        "\n",
        "Write a Python program to train a Na√Øve Bayes Classifier and evaluate its performance using Log Loss\n",
        "(Cross-Entropy Loss)\n",
        "\n",
        " Write a Python program to train an SVM Classifier and visualize the Confusion Matrix using seaborn\n",
        "\n",
        "Write a Python program to train an SVM Regressor (SVR) and evaluate its performance using Mean Absolute\n",
        "Error (MAE) instead of MSE\n",
        "\n",
        " Write a Python program to train a Na√Øve Bayes classifier and evaluate its performance using the ROC-AUC\n",
        "score\n",
        "\n",
        " Write a Python program to train an SVM Classifier and visualize the Precision-Recall Curve."
      ],
      "metadata": {
        "id": "jyI1n3UFmQdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB # NEW: Switched to Gaussian Naive Bayes\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from statistics import mean, stdev\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the Breast Cancer dataset (binary classification: 0=malignant, 1=benign).\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Define the number of splits for cross-validation\n",
        "N_SPLITS = 5\n",
        "N_CLASSES = 2\n",
        "\n",
        "# --- 2. Setup Model Pipelines with Different Priors ---\n",
        "# Note: Feature scaling (StandardScaler) is included in the pipeline. While less\n",
        "# critical for Naive Bayes than SVM, it is generally good practice.\n",
        "\n",
        "# A. Naive Bayes with Default Priors (Priors are estimated from class frequencies in training folds)\n",
        "pipeline_default_priors = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    GaussianNB(priors=None)\n",
        ")\n",
        "\n",
        "# B. Naive Bayes with Custom (Uniform) Priors (Manually set to 50/50, ignoring actual class imbalance)\n",
        "# The custom priors list MUST sum to 1.0. Order corresponds to class labels (0, 1).\n",
        "custom_priors = [0.5, 0.5]\n",
        "pipeline_custom_priors = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    GaussianNB(priors=custom_priors)\n",
        ")\n",
        "\n",
        "# --- 3. Setup Stratified K-Fold Cross-Validation ---\n",
        "cv_strategy = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"Dataset: Breast Cancer (Total Samples: {X.shape[0]})\")\n",
        "print(f\"Validation Strategy: Stratified {N_SPLITS}-Fold Cross-Validation (Shuffle=True)\")\n",
        "print(\"Starting cross-validation for both Na√Øve Bayes models...\")\n",
        "\n",
        "# --- 4. Evaluate Models using Cross-Validation ---\n",
        "\n",
        "# Evaluate model with default priors\n",
        "scores_default = cross_val_score(\n",
        "    pipeline_default_priors,\n",
        "    X,\n",
        "    y,\n",
        "    cv=cv_strategy,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Evaluate model with custom priors\n",
        "scores_custom = cross_val_score(\n",
        "    pipeline_custom_priors,\n",
        "    X,\n",
        "    y,\n",
        "    cv=cv_strategy,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate statistics\n",
        "mean_default = mean(scores_default)\n",
        "std_default = stdev(scores_default)\n",
        "\n",
        "mean_custom = mean(scores_custom)\n",
        "std_custom = stdev(scores_custom)\n",
        "\n",
        "\n",
        "# --- 5. Print Comparison Results ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NA√èVE BAYES ACCURACY COMPARISON: DEFAULT vs. CUSTOM PRIORS\")\n",
        "print(\"=\"*80)\n",
        "print(\"-\" * 80)\n",
        "print(f\"| {'Model Configuration':<45} | {'Mean Accuracy':<15} | {'Std Dev':<10} |\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"| {'1. Default Priors (Estimated from Data)':<45} | {mean_default:.4f} ({(mean_default*100):.2f}%) | {std_default:.4f} |\")\n",
        "print(f\"| {'2. Custom Priors (Uniform [0.5, 0.5])':<45} | {mean_custom:.4f} ({(mean_custom*100):.2f}%) | {std_custom:.4f} |\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Provide analysis\n",
        "if mean_default > mean_custom:\n",
        "    print(\"\\nConclusion: The model using default priors (estimated from the training data) performed better.\")\n",
        "    print(\"This indicates that incorporating the actual class distribution is important for this dataset.\")\n",
        "elif mean_custom > mean_default:\n",
        "    print(\"\\nConclusion: The model using uniform custom priors performed better.\")\n",
        "    print(\"This might suggest that the small difference in class frequency is irrelevant or misleading in this context.\")\n",
        "else:\n",
        "    print(\"\\nConclusion: Both prior settings resulted in the exact same mean accuracy.\")\n",
        "\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "id": "pihIlx5sm7mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC # Switched back to SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_selection import RFE # NEW: Import for Recursive Feature Elimination\n",
        "from statistics import mean, stdev\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the Breast Cancer dataset (binary classification).\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "N_FEATURES = X.shape[1] # Total number of features (30 for Breast Cancer)\n",
        "\n",
        "# Define the number of splits for cross-validation\n",
        "N_SPLITS = 5\n",
        "# Define the number of features to select using RFE (arbitrarily chosen 15 out of 30)\n",
        "N_FEATURES_TO_SELECT = 15\n",
        "\n",
        "# --- 2. Setup Base Model and Cross-Validation ---\n",
        "# Base SVM Classifier (Linear kernel is required for RFE to rank features based on coefficients)\n",
        "base_svc = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "\n",
        "# Standard Scaler for preprocessing\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Stratified K-Fold Cross-Validation strategy\n",
        "cv_strategy = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "# --- 3. Setup Model Pipelines ---\n",
        "\n",
        "# A. Pipeline with ALL Features (Standard SVC)\n",
        "pipeline_all_features = make_pipeline(\n",
        "    scaler,\n",
        "    base_svc\n",
        ")\n",
        "\n",
        "# B. Pipeline with RFE Feature Selection\n",
        "# RFE wraps the SVC, fits it, ranks features, and recursively eliminates the worst ones\n",
        "# until N_FEATURES_TO_SELECT remain.\n",
        "pipeline_rfe_features = make_pipeline(\n",
        "    scaler,\n",
        "    RFE(estimator=base_svc, n_features_to_select=N_FEATURES_TO_SELECT),\n",
        "    base_svc # The RFE output is passed to a final SVC for training/scoring\n",
        ")\n",
        "\n",
        "print(f\"Dataset: Breast Cancer (Total Samples: {X.shape[0]}, Total Features: {N_FEATURES})\")\n",
        "print(f\"Validation Strategy: Stratified {N_SPLITS}-Fold Cross-Validation\")\n",
        "print(f\"RFE Target: Selecting {N_FEATURES_TO_SELECT} out of {N_FEATURES} features.\")\n",
        "print(\"Starting cross-validation for both models...\")\n",
        "\n",
        "# --- 4. Evaluate Models using Cross-Validation ---\n",
        "\n",
        "# Evaluate model with ALL features\n",
        "scores_all = cross_val_score(\n",
        "    pipeline_all_features,\n",
        "    X,\n",
        "    y,\n",
        "    cv=cv_strategy,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Evaluate model with RFE-selected features\n",
        "scores_rfe = cross_val_score(\n",
        "    pipeline_rfe_features,\n",
        "    X,\n",
        "    y,\n",
        "    cv=cv_strategy,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate statistics\n",
        "mean_all = mean(scores_all)\n",
        "std_all = stdev(scores_all)\n",
        "\n",
        "mean_rfe = mean(scores_rfe)\n",
        "std_rfe = stdev(scores_rfe)\n",
        "\n",
        "\n",
        "# --- 5. Print Comparison Results ---\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"SVM ACCURACY COMPARISON: ALL FEATURES vs. RECURSIVE FEATURE ELIMINATION (RFE)\")\n",
        "print(\"=\"*90)\n",
        "print(\"-\" * 90)\n",
        "print(f\"| {'Model Configuration':<45} | {'Mean Accuracy':<15} | {'Std Dev':<10} | {'Features':<10} |\")\n",
        "print(\"-\" * 90)\n",
        "print(f\"| {'1. Standard SVM (All Features)':<45} | {mean_all:.4f} ({(mean_all*100):.2f}%) | {std_all:.4f} | {N_FEATURES:<10} |\")\n",
        "print(f\"| {'2. RFE-Optimized SVM':<45} | {mean_rfe:.4f} ({(mean_rfe*100):.2f}%) | {std_rfe:.4f} | {N_FEATURES_TO_SELECT:<10} |\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "# Provide analysis\n",
        "print(\"\\nAnalysis of Results:\")\n",
        "if mean_rfe > mean_all:\n",
        "    print(f\"-> RFE improved the model performance! By reducing features from {N_FEATURES} to {N_FEATURES_TO_SELECT}, the model became slightly more accurate, potentially by eliminating noisy or redundant features.\")\n",
        "elif mean_all > mean_rfe:\n",
        "    print(f\"-> RFE led to a minor decrease in performance. This suggests that the features eliminated were still important, or the default number of features ({N_FEATURES_TO_SELECT}) was too small.\")\n",
        "else:\n",
        "    print(\"-> Both models achieved identical mean accuracy, indicating that feature selection did not have a measurable impact on the generalized accuracy in this case.\")\n",
        "print(\"=\"*90)"
      ],
      "metadata": {
        "id": "qChnIer2nLU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate # CHANGED: Using cross_validate for multiple metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_selection import RFE\n",
        "# Removed: from statistics import mean, stdev (Will use numpy.mean/std)\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the Breast Cancer dataset (binary classification).\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "N_FEATURES = X.shape[1] # Total number of features (30 for Breast Cancer)\n",
        "\n",
        "# Define the number of splits for cross-validation\n",
        "N_SPLITS = 5\n",
        "# Define the number of features to select using RFE (arbitrarily chosen 15 out of 30)\n",
        "N_FEATURES_TO_SELECT = 15\n",
        "# NEW: Define metrics for multi-metric evaluation\n",
        "SCORING_METRICS = ['accuracy', 'precision', 'recall', 'f1']\n",
        "\n",
        "\n",
        "# --- 2. Setup Base Model and Cross-Validation ---\n",
        "# Base SVM Classifier (Linear kernel is required for RFE to rank features based on coefficients)\n",
        "base_svc = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "\n",
        "# Standard Scaler for preprocessing\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Stratified K-Fold Cross-Validation strategy\n",
        "cv_strategy = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "# --- 3. Setup Model Pipelines ---\n",
        "\n",
        "# A. Pipeline with ALL Features (Standard SVC)\n",
        "pipeline_all_features = make_pipeline(\n",
        "    scaler,\n",
        "    base_svc\n",
        ")\n",
        "\n",
        "# B. Pipeline with RFE Feature Selection\n",
        "# RFE wraps the SVC, fits it, ranks features, and recursively eliminates the worst ones\n",
        "# until N_FEATURES_TO_SELECT remain.\n",
        "pipeline_rfe_features = make_pipeline(\n",
        "    scaler,\n",
        "    RFE(estimator=base_svc, n_features_to_select=N_FEATURES_TO_SELECT),\n",
        "    base_svc # The RFE output is passed to a final SVC for training/scoring\n",
        ")\n",
        "\n",
        "print(f\"Dataset: Breast Cancer (Total Samples: {X.shape[0]}, Total Features: {N_FEATURES})\")\n",
        "print(f\"Validation Strategy: Stratified {N_SPLITS}-Fold Cross-Validation\")\n",
        "print(f\"RFE Target: Selecting {N_FEATURES_TO_SELECT} out of {N_FEATURES} features.\")\n",
        "print(\"Starting cross-validation for both models using Precision, Recall, and F1-Score...\")\n",
        "\n",
        "# --- 4. Evaluate Models using Cross-Validation ---\n",
        "\n",
        "# Evaluate model with ALL features\n",
        "results_all = cross_validate( # CHANGED to cross_validate\n",
        "    pipeline_all_features,\n",
        "    X,\n",
        "    y,\n",
        "    cv=cv_strategy,\n",
        "    scoring=SCORING_METRICS, # Use list of metrics\n",
        "    n_jobs=-1,\n",
        "    return_train_score=False # Only need test scores\n",
        ")\n",
        "\n",
        "# Evaluate model with RFE-selected features\n",
        "results_rfe = cross_validate( # CHANGED to cross_validate\n",
        "    pipeline_rfe_features,\n",
        "    X,\n",
        "    y,\n",
        "    cv=cv_strategy,\n",
        "    scoring=SCORING_METRICS, # Use list of metrics\n",
        "    n_jobs=-1,\n",
        "    return_train_score=False\n",
        ")\n",
        "\n",
        "# --- 5. Calculate and Prepare Results ---\n",
        "\n",
        "def get_stats(results_dict):\n",
        "    \"\"\"Calculates mean and std dev for requested metrics from cross_validate results.\"\"\"\n",
        "    stats = {}\n",
        "    for metric in SCORING_METRICS:\n",
        "        scores = results_dict[f'test_{metric}']\n",
        "        stats[metric] = {\n",
        "            'mean': np.mean(scores),\n",
        "            'std': np.std(scores)\n",
        "        }\n",
        "    return stats\n",
        "\n",
        "stats_all = get_stats(results_all)\n",
        "stats_rfe = get_stats(results_rfe)\n",
        "\n",
        "\n",
        "# --- 6. Print Comparison Results ---\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"SVM ACCURACY COMPARISON: ALL FEATURES vs. RECURSIVE FEATURE ELIMINATION (RFE)\")\n",
        "print(\"=\"*90)\n",
        "print(f\"Features: | 1. Standard SVM: {N_FEATURES} | 2. RFE-Optimized SVM: {N_FEATURES_TO_SELECT}\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "# Print Header Row\n",
        "print(f\"| {'Model':<15} | {'Mean Precision':<15} | {'Std Precision':<15} | {'Mean Recall':<15} | {'Std Recall':<15} | {'Mean F1-Score':<15} | {'Std F1-Score':<15} |\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "# Print All Features Results\n",
        "print(f\"| {'All Features':<15} | {stats_all['precision']['mean']:.4f} | {stats_all['precision']['std']:.4f} | {stats_all['recall']['mean']:.4f} | {stats_all['recall']['std']:.4f} | {stats_all['f1']['mean']:.4f} | {stats_all['f1']['std']:.4f} |\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "# Print RFE Results\n",
        "print(f\"| {'RFE-Optimized':<15} | {stats_rfe['precision']['mean']:.4f} | {stats_rfe['precision']['std']:.4f} | {stats_rfe['recall']['mean']:.4f} | {stats_rfe['recall']['std']:.4f} | {stats_rfe['f1']['mean']:.4f} | {stats_rfe['f1']['std']:.4f} |\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "print(f\"\\nOverall Mean Accuracy (All Features): {stats_all['accuracy']['mean']:.4f}\")\n",
        "print(f\"Overall Mean Accuracy (RFE-Optimized): {stats_rfe['accuracy']['mean']:.4f}\")\n",
        "\n",
        "\n",
        "# Provide analysis based on F1-Score, as it balances Precision and Recall\n",
        "f1_all = stats_all['f1']['mean']\n",
        "f1_rfe = stats_rfe['f1']['mean']\n",
        "\n",
        "print(\"\\nAnalysis of Results (Based on F1-Score):\")\n",
        "if f1_rfe > f1_all:\n",
        "    print(f\"-> RFE improved the model performance! The RFE-optimized model achieved a higher F1-Score ({f1_rfe:.4f} vs {f1_all:.4f}) with fewer features.\")\n",
        "elif f1_all > f1_rfe:\n",
        "    print(f\"-> The Standard SVM performed better. The RFE process resulted in a lower F1-Score ({f1_rfe:.4f} vs {f1_all:.4f}), suggesting important features were removed.\")\n",
        "else:\n",
        "    print(\"-> Both models achieved identical mean F1-Score, indicating that feature selection did not have a measurable impact on the generalized performance.\")\n",
        "print(\"=\"*90)"
      ],
      "metadata": {
        "id": "SAr6jbw8nX5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.naive_bayes import GaussianNB # NEW: Switched to Gaussian Naive Bayes\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "# Removed RFE import as it is not needed for this evaluation\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the Breast Cancer dataset (binary classification).\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "N_FEATURES = X.shape[1] # Total number of features (30 for Breast Cancer)\n",
        "\n",
        "# Define the number of splits for cross-validation\n",
        "N_SPLITS = 5\n",
        "# Define metrics for evaluation. 'neg_log_loss' is used because lower log loss is better,\n",
        "# and scikit-learn's scoring convention requires higher scores to be better.\n",
        "SCORING_METRICS = ['accuracy', 'neg_log_loss']\n",
        "\n",
        "\n",
        "# --- 2. Setup Base Model and Cross-Validation ---\n",
        "# Base Na√Øve Bayes Classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Standard Scaler for preprocessing (good practice)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Stratified K-Fold Cross-Validation strategy\n",
        "cv_strategy = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "# --- 3. Setup Model Pipeline ---\n",
        "\n",
        "# Pipeline for Gaussian Na√Øve Bayes\n",
        "nb_pipeline = make_pipeline(\n",
        "    scaler,\n",
        "    nb_classifier\n",
        ")\n",
        "\n",
        "print(f\"Dataset: Breast Cancer (Total Samples: {X.shape[0]}, Total Features: {N_FEATURES})\")\n",
        "print(f\"Classifier: Gaussian Na√Øve Bayes\")\n",
        "print(f\"Validation Strategy: Stratified {N_SPLITS}-Fold Cross-Validation\")\n",
        "print(\"Starting cross-validation using Accuracy and Negative Log Loss...\")\n",
        "\n",
        "# --- 4. Evaluate Model using Cross-Validation ---\n",
        "\n",
        "results_nb = cross_validate(\n",
        "    nb_pipeline,\n",
        "    X,\n",
        "    y,\n",
        "    cv=cv_strategy,\n",
        "    scoring=SCORING_METRICS,\n",
        "    n_jobs=-1,\n",
        "    return_train_score=False\n",
        ")\n",
        "\n",
        "# --- 5. Calculate and Prepare Results ---\n",
        "\n",
        "# Log Loss (Negative scores are converted to positive loss values)\n",
        "log_loss_scores = -results_nb['test_neg_log_loss']\n",
        "mean_log_loss = np.mean(log_loss_scores)\n",
        "std_log_loss = np.std(log_loss_scores)\n",
        "\n",
        "# Accuracy\n",
        "accuracy_scores = results_nb['test_accuracy']\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "\n",
        "\n",
        "# --- 6. Print Comparison Results ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NA√èVE BAYES PERFORMANCE EVALUATION (Log Loss & Accuracy)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Validation Folds: {N_SPLITS}\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"| {'Metric':<20} | {'Mean Score':<20} | {'Std Dev':<20} |\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"| {'Log Loss (Cross-Entropy)':<20} | {mean_log_loss:.4f} | {std_log_loss:.4f} |\")\n",
        "print(f\"| {'Accuracy':<20} | {mean_accuracy:.4f} ({(mean_accuracy*100):.2f}%) | {std_accuracy:.4f} |\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"-> Mean Log Loss of {mean_log_loss:.4f}: This indicates the average cross-entropy between the predicted probabilities and the true labels. Lower values are better, representing a more confident and accurate model.\")\n",
        "print(f\"-> Mean Accuracy of {mean_accuracy:.4f}: This represents the average proportion of correctly classified samples across all {N_SPLITS} folds.\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "id": "6r7l5UYKnZJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # NEW: For plotting\n",
        "import seaborn as sns # NEW: For visualizing the Confusion Matrix\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split # CHANGED: Using train_test_split for a single test set\n",
        "from sklearn.svm import SVC # CHANGED: Switched back to SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report # NEW: For evaluation metrics and matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the Breast Cancer dataset (binary classification).\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "N_FEATURES = X.shape[1] # Total number of features (30 for Breast Cancer)\n",
        "TARGET_NAMES = load_breast_cancer().target_names # Names for labels (malignant, benign)\n",
        "\n",
        "\n",
        "# --- 2. Data Split ---\n",
        "# Split the data into training and testing sets for a single evaluation.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- 3. Setup Model Pipeline ---\n",
        "# Use an RBF kernel SVM, which generally performs well.\n",
        "svc_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
        "\n",
        "# Pipeline for SVC with Standardization\n",
        "svc_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    svc_classifier\n",
        ")\n",
        "\n",
        "print(f\"Dataset: Breast Cancer (Total Samples: {X.shape[0]}, Features: {N_FEATURES})\")\n",
        "print(f\"Classifier: Support Vector Classifier (RBF Kernel)\")\n",
        "print(f\"Evaluation: Standard 70/30 Train/Test Split\")\n",
        "print(\"Training model and generating Confusion Matrix...\")\n",
        "\n",
        "# --- 4. Train Model and Predict ---\n",
        "\n",
        "# Train the model\n",
        "svc_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svc_pipeline.predict(X_test)\n",
        "\n",
        "# --- 5. Evaluate Performance ---\n",
        "\n",
        "# Calculate Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=TARGET_NAMES)\n",
        "\n",
        "# --- 6. Plot Confusion Matrix ---\n",
        "\n",
        "# Set a figure size for better visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Create the seaborn heatmap\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True, # Annotate cells with the numeric value\n",
        "    fmt='d', # Format as integer\n",
        "    cmap='Blues', # Color map\n",
        "    cbar=False, # Do not show the color bar\n",
        "    xticklabels=TARGET_NAMES, # X-axis labels (Predicted)\n",
        "    yticklabels=TARGET_NAMES # Y-axis labels (Actual)\n",
        ")\n",
        "plt.title('Confusion Matrix for SVM Classifier')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "# Save the plot to a file (this step is necessary to display it in the environment)\n",
        "plt.savefig('confusion_matrix_svc.png')\n",
        "# Close the plot to free memory\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# --- 7. Print Results ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SVM PERFORMANCE EVALUATION (RBF Kernel)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"-\" * 80)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "print(\"-\" * 80)\n",
        "print(\"The Confusion Matrix is displayed above/as an output file (confusion_matrix_svc.png).\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "7Z07DN24niDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing # CHANGED: Switched to regression dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR # CHANGED: Switched to Support Vector Regressor (SVR)\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score # NEW: For regression metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the California Housing dataset (regression problem).\n",
        "housing = fetch_california_housing(as_frame=False)\n",
        "X, y = housing.data, housing.target\n",
        "N_FEATURES = X.shape[1] # Total number of features (8 for California Housing)\n",
        "\n",
        "# --- 2. Data Split ---\n",
        "# Split the data into training and testing sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# --- 3. Setup Model Pipeline ---\n",
        "# Use an RBF kernel SVR, which is a common choice for non-linear regression.\n",
        "svr_regressor = SVR(kernel='rbf', C=10.0, gamma='scale') # Increased C for better fitting\n",
        "\n",
        "# Pipeline for SVR with Standardization\n",
        "svr_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    svr_regressor\n",
        ")\n",
        "\n",
        "print(f\"Dataset: California Housing (Total Samples: {X.shape[0]}, Features: {N_FEATURES})\")\n",
        "print(f\"Model: Support Vector Regressor (SVR, RBF Kernel)\")\n",
        "print(f\"Evaluation: Standard 70/30 Train/Test Split\")\n",
        "print(\"Training model and evaluating performance...\")\n",
        "\n",
        "# --- 4. Train Model and Predict ---\n",
        "\n",
        "# Train the model\n",
        "svr_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svr_pipeline.predict(X_test)\n",
        "\n",
        "# --- 5. Evaluate Performance (Mean Absolute Error - MAE) ---\n",
        "\n",
        "# Calculate MAE (The requested metric)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Calculate other common regression metrics for context\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# --- 6. Visualize Prediction vs. Actual (For Context) ---\n",
        "\n",
        "# Create a figure to plot predictions vs. actual values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
        "# Plot the ideal 45-degree line where predictions equal actuals\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
        "\n",
        "plt.title('SVR: Actual vs. Predicted House Prices')\n",
        "plt.xlabel('True Values (Actual Price in $100,000s)')\n",
        "plt.ylabel('Predicted Values (Price in $100,000s)')\n",
        "plt.grid(True)\n",
        "# Save the plot to a file\n",
        "plt.savefig('svr_prediction_vs_actual.png')\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# --- 7. Print Results ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SVR PERFORMANCE EVALUATION (California Housing)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\") # Requested Metric\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R-squared (R2 Score): {r2:.4f}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"-> MAE of {mae:.4f}: This means the average magnitude of error in predicting the house price is {mae:.4f} units (where a unit is $100,000). For example, if MAE is 0.5, the model is off by $50,000 on average.\")\n",
        "print(\"-> The scatter plot (svr_prediction_vs_actual.png) shows how closely predictions align with the true values.\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "jz-NIyi2nv36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Removed matplotlib and seaborn as the requested output is a single score\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer # CHANGED: Switched to classification dataset\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score # CHANGED: Using cross_val_score and StratifiedKFold\n",
        "from sklearn.naive_bayes import GaussianNB # CHANGED: Switched to Gaussian Na√Øve Bayes\n",
        "# Removed regression metric imports and kept general imports\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the Breast Cancer dataset (binary classification).\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "N_FEATURES = X.shape[1]\n",
        "\n",
        "# Define the number of splits for cross-validation\n",
        "N_SPLITS = 5\n",
        "# Define the scoring metric\n",
        "SCORING_METRIC = 'roc_auc'\n",
        "\n",
        "\n",
        "# --- 2. Setup Base Model and Cross-Validation ---\n",
        "# Base Na√Øve Bayes Classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Stratified K-Fold Cross-Validation strategy\n",
        "cv_strategy = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "# --- 3. Setup Model Pipeline ---\n",
        "\n",
        "# Pipeline for Gaussian Na√Øve Bayes with Standardization\n",
        "nb_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    nb_classifier\n",
        ")\n",
        "\n",
        "print(f\"Dataset: Breast Cancer (Total Samples: {X.shape[0]}, Total Features: {N_FEATURES})\")\n",
        "print(f\"Classifier: Gaussian Na√Øve Bayes\")\n",
        "print(f\"Validation Strategy: Stratified {N_SPLITS}-Fold Cross-Validation\")\n",
        "print(\"Starting cross-validation using ROC-AUC score...\")\n",
        "\n",
        "# --- 4. Evaluate Model using Cross-Validation ---\n",
        "\n",
        "# Calculate ROC-AUC score for each fold. AUC uses predicted probabilities.\n",
        "auc_scores = cross_val_score(\n",
        "    nb_pipeline,\n",
        "    X,\n",
        "    y,\n",
        "    cv=cv_strategy,\n",
        "    scoring=SCORING_METRIC, # Score using Area Under the ROC Curve\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# --- 5. Calculate and Prepare Results ---\n",
        "\n",
        "mean_auc = np.mean(auc_scores)\n",
        "std_auc = np.std(auc_scores)\n",
        "\n",
        "\n",
        "# --- 6. Print Results ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NA√èVE BAYES PERFORMANCE EVALUATION (ROC-AUC)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Validation Folds: {N_SPLITS}\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"| {'Metric':<20} | {'Mean Score':<20} | {'Std Dev':<20} |\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"| {'ROC AUC Score':<20} | {mean_auc:.4f} | {std_auc:.4f} |\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"-> Mean ROC-AUC of {mean_auc:.4f}: The ROC-AUC score represents the model's ability to distinguish between classes. A score close to 1.0 is excellent, while 0.5 is no better than random guessing.\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "vn0ntWcSn3Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # NEW: For plotting the curve\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split # CHANGED: Using train_test_split for a single test set\n",
        "from sklearn.svm import SVC # CHANGED: Switched back to SVC\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, average_precision_score # NEW: For PR Curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# --- 1. Load the Dataset ---\n",
        "# We use the Breast Cancer dataset (binary classification).\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "N_FEATURES = X.shape[1]\n",
        "TARGET_NAMES = load_breast_cancer().target_names\n",
        "\n",
        "# --- 2. Data Split ---\n",
        "# Split the data into training and testing sets for a single evaluation.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- 3. Setup Model Pipeline ---\n",
        "# Use an RBF kernel SVM. Set probability=True to enable predict_proba,\n",
        "# which is needed for the Precision-Recall Curve.\n",
        "# Note: Enabling probability=True adds computational cost due to Platt Scaling.\n",
        "svc_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True)\n",
        "\n",
        "# Pipeline for SVC with Standardization\n",
        "svc_pipeline = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    svc_classifier\n",
        ")\n",
        "\n",
        "print(f\"Dataset: Breast Cancer (Total Samples: {X.shape[0]}, Features: {N_FEATURES})\")\n",
        "print(f\"Classifier: Support Vector Classifier (RBF Kernel with Probability Output)\")\n",
        "print(f\"Evaluation: Standard 70/30 Train/Test Split\")\n",
        "print(\"Training model and generating Precision-Recall Curve...\")\n",
        "\n",
        "# --- 4. Train Model and Get Probabilities ---\n",
        "\n",
        "# Train the model\n",
        "svc_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Get decision function scores (or probabilities for positive class)\n",
        "# For SVC with probability=True, predict_proba returns probabilities\n",
        "y_scores = svc_pipeline.predict_proba(X_test)[:, 1] # Probability of the positive class\n",
        "\n",
        "# --- 5. Calculate Precision-Recall Curve components ---\n",
        "\n",
        "# Calculate precision, recall, and thresholds\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Calculate Average Precision Score\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "# --- 6. Plot Precision-Recall Curve ---\n",
        "\n",
        "# Create a figure for the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Use PrecisionRecallDisplay to plot the curve\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=avg_precision)\n",
        "disp.plot(ax=plt.gca(), name=f'SVM (AP={avg_precision:.2f})')\n",
        "\n",
        "plt.title('Precision-Recall Curve for SVM Classifier')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.grid(True)\n",
        "plt.legend(loc=\"lower left\")\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig('precision_recall_curve_svc.png')\n",
        "plt.close()\n",
        "\n",
        "# --- 7. Print Results ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SVM PERFORMANCE EVALUATION (PRECISION-RECALL)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Average Precision Score (AP): {avg_precision:.4f}\")\n",
        "print(\"-\" * 80)\n",
        "print(\"The Precision-Recall Curve is displayed above/as an output file (precision_recall_curve_svc.png).\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "HWTxa7NPoGGw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}